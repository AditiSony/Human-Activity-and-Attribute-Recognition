{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c471051d-9333-4780-aeec-cb3565d091a5",
   "metadata": {},
   "source": [
    "# Sensor Based Human Activity and Attribute Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f819a78-ca52-4d9a-9cef-97858f3f1df0",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c088864-7150-491f-8a8f-8f117ca4b857",
   "metadata": {},
   "source": [
    "Smartphones have become must have necessity these days and with time they have evolved from just being means of communication to one-stop-shop gadget with wide variety of features and applications. These days most of the smartphones have built-in Accelerometer, Gyroscope, Magnetometer and lots of applications use these to monitor person's activities.\n",
    "\n",
    "Recently there has been an increasing trend for use of such applications for monitoring one's health or fitness. These provide many benefits from monitoring the fitness levels to providing intervention or guidance at the correct time for improving one's health. There are numerous literature where different type of machine learning algorithms have been used in prediction or classification of activities based on the sensor data from the smartphones. My motivation here is to check if alongside recognising the activity, is it possible to predict some of the personal attributes (e.g., height, weight, age, gender) of the individual performing those activities from the same sensor data collected from the smartphone.\n",
    "\n",
    "If it is possible then maybe these can also help in understanding other underlying health conditions like high BMI levels or other movement disorders early."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c683c85-ee48-422d-bdf5-d6dada03b99d",
   "metadata": {},
   "source": [
    "## Description of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d2769b-824c-4d60-9323-498cc82f30be",
   "metadata": {},
   "source": [
    "The dataset (MotionSense Data Set) is part of research work done by Malekzadeh et al. from Queen Mary University of London. It is a time-series data generated by accelerometer and gyroscope sensors (attitude, gravity, userAcceleration, and rotationRate). It is collected with an iPhone 6s kept in the participant's front pocket. A total of 24 participants in a range of gender, age, weight, and height performed 6 activities in 15 trials in the same environment and conditions: downstairs, upstairs, walking, jogging, sitting, and standing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a5c24-d340-4afe-95fa-b73a2a2879f8",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699dae71-9604-412b-96b9-ea0c33937d5e",
   "metadata": {},
   "source": [
    "To verify if it is possible to predict the activity as well as other personal attributes of subjects from the sensor data provided by using different models and to evaluate models for their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997f4d6-9070-49c4-b6a5-2556e1056bd0",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b102da38-6343-4d31-8912-4fe4f2d2fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import os\n",
    "import scipy.io\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Dropout, Flatten\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f0fc63-1622-4f29-875e-8e0a9eb7e6de",
   "metadata": {},
   "source": [
    "## Loading Data and Initial pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb7edb4-54d0-4193-b590-dbc42f946021",
   "metadata": {},
   "source": [
    "We will only use data from the folder A_DeviceMotion as it contains data from all the sensors. We will label the data with the activity, trial, subject and demographics information like Gender, Height, Weight and Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae95f7d-9774-4f0e-96ca-dcb98aefa837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath\n",
    "Filepath= ('C:/Users/kapil/Downloads/Machine_Learning/Project/Data/A_DeviceMotion_data')\n",
    "Filepath01= ('C:/Users/kapil/Downloads/Machine_Learning/Project/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a39862c-0f43-4652-a19f-524553c9616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Filenames in each folder of activity and Trial for each subject, Subjects_info file\n",
    "Filenames_dws_1= glob(Filepath + '/dws_1/*.csv')\n",
    "Filenames_dws_11= glob(Filepath + '/dws_11/*.csv')\n",
    "Filenames_dws_2= glob( Filepath + '/dws_2/*.csv')\n",
    "Filenames_jog_16= glob(Filepath + '/jog_16/*.csv')\n",
    "Filenames_jog_9= glob(Filepath + '/jog_9/*.csv')\n",
    "Filenames_sit_13= glob(Filepath + '/sit_13/*.csv')\n",
    "Filenames_sit_5= glob(Filepath + '/sit_5/*.csv')\n",
    "Filenames_std_14= glob(Filepath + '/std_14/*.csv')\n",
    "Filenames_std_6= glob(Filepath + '/std_6/*.csv')\n",
    "Filenames_ups_12= glob(Filepath + '/ups_12/*.csv')\n",
    "Filenames_ups_3= glob(Filepath + '/ups_3/*.csv')\n",
    "Filenames_ups_4= glob(Filepath + '/ups_4/*.csv')\n",
    "Filenames_wlk_15= glob(Filepath + '/wlk_15/*.csv')\n",
    "Filenames_wlk_7= glob(Filepath + '/wlk_7/*.csv')\n",
    "Filenames_wlk_8= glob(Filepath + '/wlk_8/*.csv')\n",
    "Filename_sub_info= Filepath01+ '/data_subjects_info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa8306e-c2c3-4547-ba5e-64772cbb4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary for activity labels\n",
    "Act_labels= {'dws': 0, 'jog': 1, 'sit': 2, 'std': 3, 'ups': 4, 'wlk': 5}\n",
    "Act_code= list(Act_labels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e89d5fa8-5571-4bd7-a829-b1308361d27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1412865, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating labeled dataset\n",
    "Dataframe_dws_1= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 0, Trial= 1) for f in Filenames_dws_1])\n",
    "Dataframe_dws_11= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 0, Trial= 11) for f in Filenames_dws_11])\n",
    "Dataframe_dws_2= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 0, Trial= 2) for f in Filenames_dws_2])\n",
    "Dataframe_jog_16= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 1, Trial= 16) for f in Filenames_jog_16])\n",
    "Dataframe_jog_9= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 1, Trial= 9) for f in Filenames_jog_9])\n",
    "Dataframes_sit_13= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 2, Trial= 13) for f in Filenames_sit_13])\n",
    "Dataframes_sit_5= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 2, Trial= 5) for f in Filenames_sit_5])\n",
    "Dataframes_std_14= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 3, Trial= 14) for f in Filenames_std_14])\n",
    "Dataframes_std_6= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 3, Trial= 6) for f in Filenames_std_6])\n",
    "Dataframes_ups_12= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 4, Trial= 12) for f in Filenames_ups_12])\n",
    "Dataframes_ups_3= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 4, Trial= 3) for f in Filenames_ups_3])\n",
    "Dataframes_ups_4= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 4, Trial= 4) for f in Filenames_ups_4])\n",
    "Dataframes_wlk_15= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 5, Trial= 15) for f in Filenames_wlk_15])\n",
    "Dataframes_wlk_7= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 5, Trial= 7) for f in Filenames_wlk_7])\n",
    "Dataframes_wlk_8= pd.concat([pd.read_csv(f).assign(Subject=os.path.basename(f), Activity= 5, Trial= 8) for f in Filenames_wlk_8])\n",
    "Dataframes_list = [Dataframe_dws_1, Dataframe_dws_11, Dataframe_dws_2, Dataframe_jog_16, Dataframe_jog_9, Dataframes_sit_13, Dataframes_sit_5, Dataframes_std_14, Dataframes_std_6, Dataframes_ups_12, Dataframes_ups_3, Dataframes_ups_4,\n",
    "                    Dataframes_wlk_15, Dataframes_wlk_7, Dataframes_wlk_8]\n",
    "Dataset= pd.concat(Dataframes_list)\n",
    "Dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081c7be9-5305-43a7-9d63-5402a072ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the filepath to subject code\n",
    "Dataset['Subject'].replace({\"sub_1.csv\":1, \"sub_2.csv\":2, \"sub_3.csv\":3, \"sub_4.csv\":4, \"sub_5.csv\":5, \"sub_6.csv\":6, \"sub_7.csv\":7, \"sub_8.csv\":8, \"sub_9.csv\":9, \"sub_10.csv\":10, \"sub_11.csv\":11, \"sub_12.csv\":12, \"sub_13.csv\":13, \"sub_14.csv\":14, \"sub_15.csv\":15, \"sub_16.csv\":16, \"sub_17.csv\":17, \"sub_18.csv\":18,\n",
    "                           \"sub_19.csv\":19, \"sub_20.csv\":20, \"sub_21.csv\":21, \"sub_22.csv\":22,\"sub_23.csv\":23, \"sub_24.csv\":24}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5656f005-3895-4b75-995d-62386fe7886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing datatype to int from str\n",
    "Dataset['Subject']= Dataset['Subject'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618913d4-11a7-4687-8636-0687d3cf2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Subject info file\n",
    "Sub_info= pd.read_csv(Filename_sub_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee94bfaf-9630-4ae3-aa45-9977628197d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1412865, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging subject info with the datafile\n",
    "Labeled_data= pd.merge(left=Dataset, right=Sub_info, left_on='Subject', right_on= 'code')\n",
    "Labeled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888c9ad8-1c02-4be8-8742-156120d0e6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude.roll</th>\n",
       "      <th>attitude.pitch</th>\n",
       "      <th>attitude.yaw</th>\n",
       "      <th>gravity.x</th>\n",
       "      <th>gravity.y</th>\n",
       "      <th>gravity.z</th>\n",
       "      <th>rotationRate.x</th>\n",
       "      <th>rotationRate.y</th>\n",
       "      <th>rotationRate.z</th>\n",
       "      <th>userAcceleration.x</th>\n",
       "      <th>userAcceleration.y</th>\n",
       "      <th>userAcceleration.z</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Activity</th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.528132</td>\n",
       "      <td>-0.733896</td>\n",
       "      <td>0.696372</td>\n",
       "      <td>0.741895</td>\n",
       "      <td>0.669768</td>\n",
       "      <td>-0.031672</td>\n",
       "      <td>0.316738</td>\n",
       "      <td>0.778180</td>\n",
       "      <td>1.082764</td>\n",
       "      <td>0.294894</td>\n",
       "      <td>-0.184493</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.527992</td>\n",
       "      <td>-0.716987</td>\n",
       "      <td>0.677762</td>\n",
       "      <td>0.753099</td>\n",
       "      <td>0.657116</td>\n",
       "      <td>-0.032255</td>\n",
       "      <td>0.842032</td>\n",
       "      <td>0.424446</td>\n",
       "      <td>0.643574</td>\n",
       "      <td>0.219405</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>0.114866</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.527765</td>\n",
       "      <td>-0.706999</td>\n",
       "      <td>0.670951</td>\n",
       "      <td>0.759611</td>\n",
       "      <td>0.649555</td>\n",
       "      <td>-0.032707</td>\n",
       "      <td>-0.138143</td>\n",
       "      <td>-0.040741</td>\n",
       "      <td>0.343563</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.134701</td>\n",
       "      <td>-0.167808</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.516768</td>\n",
       "      <td>-0.704678</td>\n",
       "      <td>0.675735</td>\n",
       "      <td>0.760709</td>\n",
       "      <td>0.647788</td>\n",
       "      <td>-0.041140</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>-1.048717</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>-0.008389</td>\n",
       "      <td>0.136788</td>\n",
       "      <td>0.094958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493941</td>\n",
       "      <td>-0.703918</td>\n",
       "      <td>0.672994</td>\n",
       "      <td>0.760062</td>\n",
       "      <td>0.647210</td>\n",
       "      <td>-0.058530</td>\n",
       "      <td>0.114253</td>\n",
       "      <td>-0.912890</td>\n",
       "      <td>0.047341</td>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.353996</td>\n",
       "      <td>-0.044299</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attitude.roll  attitude.pitch  attitude.yaw  gravity.x  gravity.y  \\\n",
       "0       1.528132       -0.733896      0.696372   0.741895   0.669768   \n",
       "1       1.527992       -0.716987      0.677762   0.753099   0.657116   \n",
       "2       1.527765       -0.706999      0.670951   0.759611   0.649555   \n",
       "3       1.516768       -0.704678      0.675735   0.760709   0.647788   \n",
       "4       1.493941       -0.703918      0.672994   0.760062   0.647210   \n",
       "\n",
       "   gravity.z  rotationRate.x  rotationRate.y  rotationRate.z  \\\n",
       "0  -0.031672        0.316738        0.778180        1.082764   \n",
       "1  -0.032255        0.842032        0.424446        0.643574   \n",
       "2  -0.032707       -0.138143       -0.040741        0.343563   \n",
       "3  -0.041140       -0.025005       -1.048717        0.035860   \n",
       "4  -0.058530        0.114253       -0.912890        0.047341   \n",
       "\n",
       "   userAcceleration.x  userAcceleration.y  userAcceleration.z  Subject  \\\n",
       "0            0.294894           -0.184493            0.377542        1   \n",
       "1            0.219405            0.035846            0.114866        1   \n",
       "2            0.010714            0.134701           -0.167808        1   \n",
       "3           -0.008389            0.136788            0.094958        1   \n",
       "4            0.199441            0.353996           -0.044299        1   \n",
       "\n",
       "   Activity  gender  weight  height  age  \n",
       "0         0       1     102     188   46  \n",
       "1         0       1     102     188   46  \n",
       "2         0       1     102     188   46  \n",
       "3         0       1     102     188   46  \n",
       "4         0       1     102     188   46  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearranging columns in the labelled file and dropping columns- Unnamed:0, Trial and Code\n",
    "Labeled_data= Labeled_data[['attitude.roll', 'attitude.pitch', 'attitude.yaw', 'gravity.x', 'gravity.y', 'gravity.z', 'rotationRate.x',\n",
    "                           'rotationRate.y', 'rotationRate.z', 'userAcceleration.x', 'userAcceleration.y', 'userAcceleration.z', 'Subject', 'Activity',\n",
    "                            'gender', 'weight', 'height', 'age']]\n",
    "Labeled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22fbf85-0c26-4801-84d7-504b34ea725c",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4052c815-af9f-4f03-8b0d-43cc5c8b9cc2",
   "metadata": {},
   "source": [
    "### Checking for class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "865c2bca-f9b1-4282-aa14-d6db75d09916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Labeled_data['Activity'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40daa20a-e70c-4478-bb91-c9192e4bc30d",
   "metadata": {},
   "source": [
    "The dataset is not balanced for different classes. Activities like walk, stand and sit have more data than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6881ad9-1e1e-4b9d-82b3-00d253023bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD1CAYAAABOfbKwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWrElEQVR4nO3dcazd5X3f8fenuFlJMqhNLojaMDPhtjNISceVYYs0bXVnu8pU8wdojtRxVVnyhGjXTJNWs3+sgSyBNI0VaSCh4mFYF3BZI6x0hN6ZRdM0ZrgkWYkhzHchAc8Mu7kupeqgNf3uj/Pc+vjm+LnHBt8L8fslHf1+5/t7nuc8J7Ly4fd7fuf+UlVIknQmP7bcE5AkfbQZFJKkLoNCktRlUEiSugwKSVKXQSFJ6lqx3BP4sH3mM5+ptWvXLvc0JOlj5cUXX/zDqpoYdexHLijWrl3LzMzMck9Dkj5Wknz/TMe89CRJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkrrGCook/zTJoSTfTvLlJD+RZFWS6SSH23blUPs7k8wmeTXJ5qH6DUleasfuT5JW/ytJnmj1g0nWDvWZap9xOMnUh/jdJUljWPQHd0lWA/8EWF9V/y/JPmAbsB44UFX3JNkJ7AR+I8n6dvw64KeA/5zkp6vqfeBBYAfwP4D/BGwBnga2Ayeq6tok24B7gX+YZBWwC5gECngxyf6qOvEh/m+wLNbu/L3lnsKPlO/d84XlnoL0I2vcS08rgIuTrAA+CRwFtgJ72/G9wM1tfyvweFW9V1WvAbPAhiRXApdU1XM1eKzeowv6zI/1JLCxnW1sBqaraq6FwzSDcJEkLZFFg6Kq/g/wr4DXgTeBt6vq94ErqurN1uZN4PLWZTXwxtAQR1ptddtfWD+tT1WdBN4GLuuMJUlaIosGRVt72Apcw+BS0qeS/HKvy4hadern2md4jjuSzCSZOX78eGdqkqSzNc6lp18AXquq41X158DvAn8beKtdTqJtj7X2R4CrhvqvYXCp6kjbX1g/rU+7vHUpMNcZ6zRV9VBVTVbV5MTEyD9+KEk6R+MExevATUk+2dYNNgKvAPuB+buQpoCn2v5+YFu7k+kaYB3wfLs89U6Sm9o4ty3oMz/WLcCzbR3jGWBTkpXtzGZTq0mSlsiidz1V1cEkTwLfAE4C3wQeAj4N7EuynUGY3NraH2p3Rr3c2t/R7ngCuB14BLiYwd1OT7f6w8BjSWYZnElsa2PNJbkbeKG1u6uq5j7QN5YknZUM/sP9R8fk5GR9HJ5H4e2xHy5vj5U+mCQvVtXkqGP+MluS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUtWhQJPmZJN8aev1xki8lWZVkOsnhtl051OfOJLNJXk2yeah+Q5KX2rH727Ozac/XfqLVDyZZO9Rnqn3G4SRTSJKW1KJBUVWvVtXnqupzwA3AnwJfAXYCB6pqHXCgvSfJegbPvL4O2AI8kOSiNtyDwA5gXXttafXtwImquha4D7i3jbUK2AXcCGwAdg0HkiTp/DvbS08bgf9dVd8HtgJ7W30vcHPb3wo8XlXvVdVrwCywIcmVwCVV9VwNHtT96II+82M9CWxsZxubgemqmquqE8A0p8JFkrQEzjYotgFfbvtXVNWbAG17eauvBt4Y6nOk1Va3/YX10/pU1UngbeCyzliSpCUydlAk+QTwS8DvLNZ0RK069XPtMzy3HUlmkswcP358kelJks7G2ZxR/CLwjap6q71/q11Oom2PtfoR4KqhfmuAo62+ZkT9tD5JVgCXAnOdsU5TVQ9V1WRVTU5MTJzFV5IkLeZsguKLnLrsBLAfmL8LaQp4aqi+rd3JdA2DRevn2+Wpd5Lc1NYfblvQZ36sW4Bn2zrGM8CmJCvbIvamVpMkLZEV4zRK8kng7wP/eKh8D7AvyXbgdeBWgKo6lGQf8DJwErijqt5vfW4HHgEuBp5uL4CHgceSzDI4k9jWxppLcjfwQmt3V1XNncP3lCSdo7GCoqr+lMHi8nDtBwzughrVfjewe0R9Brh+RP1dWtCMOLYH2DPOPCVJHz5/mS1J6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUtdYQZHkJ5M8meQ7SV5J8reSrEoyneRw264can9nktkkrybZPFS/IclL7dj97ZGotMemPtHqB5OsHeoz1T7jcJIpJElLatwzit8EvlZVPwt8FngF2AkcqKp1wIH2niTrGTzK9DpgC/BAkovaOA8COxg8R3tdOw6wHThRVdcC9wH3trFWAbuAG4ENwK7hQJIknX+LBkWSS4C/w+C51lTVn1XVHwFbgb2t2V7g5ra/FXi8qt6rqteAWWBDkiuBS6rquaoq4NEFfebHehLY2M42NgPTVTVXVSeAaU6FiyRpCYxzRvHXgePAv0vyzSS/leRTwBVV9SZA217e2q8G3hjqf6TVVrf9hfXT+lTVSeBtBs/oPtNYkqQlsmLMNn8T+LWqOpjkN2mXmc4gI2rVqZ9rn1MfmOxgcEmLq6++ujM1SeNYu/P3lnsKPzK+d88XlnsKH9g4ZxRHgCNVdbC9f5JBcLzVLifRtseG2l811H8NcLTV14yon9YnyQrgUmCuM9ZpquqhqpqsqsmJiYkxvpIkaVyLBkVV/V/gjSQ/00obgZeB/cD8XUhTwFNtfz+wrd3JdA2DRevn2+Wpd5Lc1NYfblvQZ36sW4Bn2zrGM8CmJCvbIvamVpMkLZFxLj0B/Brw20k+AXwX+BUGIbMvyXbgdeBWgKo6lGQfgzA5CdxRVe+3cW4HHgEuBp5uLxgslD+WZJbBmcS2NtZckruBF1q7u6pq7hy/qyTpHIwVFFX1LWByxKGNZ2i/G9g9oj4DXD+i/i4taEYc2wPsGWeekqQPn7/MliR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHWNFRRJvpfkpSTfSjLTaquSTCc53LYrh9rfmWQ2yatJNg/Vb2jjzCa5vz07m/Z87Sda/WCStUN9ptpnHE4yhSRpSZ3NGcXfq6rPVdX8I1F3Ageqah1woL0nyXoGz7y+DtgCPJDkotbnQWAHsK69trT6duBEVV0L3Afc28ZaBewCbgQ2ALuGA0mSdP59kEtPW4G9bX8vcPNQ/fGqeq+qXgNmgQ1JrgQuqarnqqqARxf0mR/rSWBjO9vYDExX1VxVnQCmORUukqQlMG5QFPD7SV5MsqPVrqiqNwHa9vJWXw28MdT3SKutbvsL66f1qaqTwNvAZZ2xJElLZMWY7T5fVUeTXA5MJ/lOp21G1KpTP9c+pz5wEF47AK6++urO1CRJZ2usM4qqOtq2x4CvMFgveKtdTqJtj7XmR4CrhrqvAY62+poR9dP6JFkBXArMdcZaOL+HqmqyqiYnJibG+UqSpDEtGhRJPpXkr87vA5uAbwP7gfm7kKaAp9r+fmBbu5PpGgaL1s+3y1PvJLmprT/ctqDP/Fi3AM+2dYxngE1JVrZF7E2tJklaIuNceroC+Eq7k3UF8B+q6mtJXgD2JdkOvA7cClBVh5LsA14GTgJ3VNX7bazbgUeAi4Gn2wvgYeCxJLMMziS2tbHmktwNvNDa3VVVcx/g+0qSztKiQVFV3wU+O6L+A2DjGfrsBnaPqM8A14+ov0sLmhHH9gB7FpunJOn88JfZkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1jR0USS5K8s0kX23vVyWZTnK4bVcOtb0zyWySV5NsHqrfkOSlduz+9khU2mNTn2j1g0nWDvWZap9xOMkUkqQldTZnFL8OvDL0fidwoKrWAQfae5KsZ/Ao0+uALcADSS5qfR4EdjB4jva6dhxgO3Ciqq4F7gPubWOtAnYBNwIbgF3DgSRJOv/GCooka4AvAL81VN4K7G37e4Gbh+qPV9V7VfUaMAtsSHIlcElVPVdVBTy6oM/8WE8CG9vZxmZguqrmquoEMM2pcJEkLYFxzyj+DfDPgb8Yql1RVW8CtO3lrb4aeGOo3ZFWW932F9ZP61NVJ4G3gcs6Y0mSlsiiQZHkHwDHqurFMcfMiFp16ufaZ3iOO5LMJJk5fvz4mNOUJI1jnDOKzwO/lOR7wOPAzyf598Bb7XISbXustT8CXDXUfw1wtNXXjKif1ifJCuBSYK4z1mmq6qGqmqyqyYmJiTG+kiRpXIsGRVXdWVVrqmotg0XqZ6vql4H9wPxdSFPAU21/P7Ct3cl0DYNF6+fb5al3ktzU1h9uW9Bnfqxb2mcU8AywKcnKtoi9qdUkSUtkxQfoew+wL8l24HXgVoCqOpRkH/AycBK4o6reb31uBx4BLgaebi+Ah4HHkswyOJPY1saaS3I38EJrd1dVzX2AOUuSztJZBUVVfR34etv/AbDxDO12A7tH1GeA60fU36UFzYhje4A9ZzNPSdKHx19mS5K6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroWDYokP5Hk+ST/M8mhJP+y1VclmU5yuG1XDvW5M8lskleTbB6q35DkpXbs/vbsbNrztZ9o9YNJ1g71mWqfcTjJFJKkJTXOGcV7wM9X1WeBzwFbktwE7AQOVNU64EB7T5L1DJ55fR2wBXggyUVtrAeBHcC69trS6tuBE1V1LXAfcG8baxWwC7gR2ADsGg4kSdL5t2hQ1MCftLc/3l4FbAX2tvpe4Oa2vxV4vKreq6rXgFlgQ5IrgUuq6rmqKuDRBX3mx3oS2NjONjYD01U1V1UngGlOhYskaQmMtUaR5KIk3wKOMfg/7oPAFVX1JkDbXt6arwbeGOp+pNVWt/2F9dP6VNVJ4G3gss5YkqQlMlZQVNX7VfU5YA2Ds4PrO80zaohO/Vz7nPrAZEeSmSQzx48f70xNknS2zuqup6r6I+DrDC7/vNUuJ9G2x1qzI8BVQ93WAEdbfc2I+ml9kqwALgXmOmMtnNdDVTVZVZMTExNn85UkSYsY566niSQ/2fYvBn4B+A6wH5i/C2kKeKrt7we2tTuZrmGwaP18uzz1TpKb2vrDbQv6zI91C/BsW8d4BtiUZGVbxN7UapKkJbJijDZXAnvbnUs/Buyrqq8meQ7Yl2Q78DpwK0BVHUqyD3gZOAncUVXvt7FuBx4BLgaebi+Ah4HHkswyOJPY1saaS3I38EJrd1dVzX2QLyxJOjuLBkVV/QHwcyPqPwA2nqHPbmD3iPoM8EPrG1X1Li1oRhzbA+xZbJ6SpPPDX2ZLkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSusZ5ZvZVSf5LkleSHEry662+Ksl0ksNtu3Koz51JZpO8mmTzUP2GJC+1Y/e3Z2fTnq/9RKsfTLJ2qM9U+4zDSaaQJC2pcc4oTgL/rKr+BnATcEeS9cBO4EBVrQMOtPe0Y9uA64AtwAPtedsADwI7gHXttaXVtwMnqupa4D7g3jbWKmAXcCOwAdg1HEiSpPNv0aCoqjer6htt/x3gFWA1sBXY25rtBW5u+1uBx6vqvap6DZgFNiS5Erikqp6rqgIeXdBnfqwngY3tbGMzMF1Vc1V1ApjmVLhIkpbAWa1RtEtCPwccBK6oqjdhECbA5a3ZauCNoW5HWm11219YP61PVZ0E3gYu64y1cF47kswkmTl+/PjZfCVJ0iLGDooknwb+I/ClqvrjXtMRterUz7XPqULVQ1U1WVWTExMTnalJks7WWEGR5McZhMRvV9XvtvJb7XISbXus1Y8AVw11XwMcbfU1I+qn9UmyArgUmOuMJUlaIuPc9RTgYeCVqvrXQ4f2A/N3IU0BTw3Vt7U7ma5hsGj9fLs89U6Sm9qYty3oMz/WLcCzbR3jGWBTkpVtEXtTq0mSlsiKMdp8HvhHwEtJvtVq/wK4B9iXZDvwOnArQFUdSrIPeJnBHVN3VNX7rd/twCPAxcDT7QWDIHosySyDM4ltbay5JHcDL7R2d1XV3Ll9VUnSuVg0KKrqvzF6rQBg4xn67AZ2j6jPANePqL9LC5oRx/YAexabpyTp/PCX2ZKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdY3zKNQ9SY4l+fZQbVWS6SSH23bl0LE7k8wmeTXJ5qH6DUleasfub49DpT0y9YlWP5hk7VCfqfYZh5PMPypVkrSExjmjeATYsqC2EzhQVeuAA+09SdYzeIzpda3PA0kuan0eBHYweIb2uqExtwMnqupa4D7g3jbWKmAXcCOwAdg1HEiSpKWxaFBU1X9l8BzrYVuBvW1/L3DzUP3xqnqvql4DZoENSa4ELqmq56qqgEcX9Jkf60lgYzvb2AxMV9VcVZ0ApvnhwJIknWfnukZxRVW9CdC2l7f6auCNoXZHWm11219YP61PVZ0E3gYu64wlSVpCH/ZidkbUqlM/1z6nf2iyI8lMkpnjx4+PNVFJ0njONSjeapeTaNtjrX4EuGqo3RrgaKuvGVE/rU+SFcClDC51nWmsH1JVD1XVZFVNTkxMnONXkiSNcq5BsR+YvwtpCnhqqL6t3cl0DYNF6+fb5al3ktzU1h9uW9BnfqxbgGfbOsYzwKYkK9si9qZWkyQtoRWLNUjyZeDvAp9JcoTBnUj3APuSbAdeB24FqKpDSfYBLwMngTuq6v021O0M7qC6GHi6vQAeBh5LMsvgTGJbG2suyd3AC63dXVW1cFFdknSeLRoUVfXFMxzaeIb2u4HdI+ozwPUj6u/SgmbEsT3AnsXmKEk6f/xltiSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnrYxEUSbYkeTXJbJKdyz0fSbqQfOSDIslFwL8FfhFYD3wxyfrlnZUkXTg+8kEBbABmq+q7VfVnwOPA1mWekyRdMFYs9wTGsBp4Y+j9EeDG4QZJdgA72ts/SfLqEs3tQvAZ4A+XexKLyb3LPQMtk4/8v8+P0b/Nv3amAx+HoMiIWp32puoh4KGlmc6FJclMVU0u9zykUfz3uTQ+DpeejgBXDb1fAxxdprlI0gXn4xAULwDrklyT5BPANmD/Ms9Jki4YH/lLT1V1MsmvAs8AFwF7qurQMk/rQuIlPX2U+e9zCaSqFm8lSbpgfRwuPUmSlpFBIUnqMigkSV0f+cVsSQJI8rMM/irDaga/pToK7K+qV5Z1YhcAzyg0liS/stxz0IUryW8w+PM9AZ5ncNt8gC/7h0LPP+960liSvF5VVy/3PHRhSvK/gOuq6s8X1D8BHKqqdcszswuDl570l5L8wZkOAVcs5VykBf4C+Cng+wvqV7ZjOo8MCg27AtgMnFhQD/Dfl3460l/6EnAgyWFO/ZHQq4FrgV9drkldKAwKDfsq8Omq+tbCA0m+vuSzkZqq+lqSn2bw2IHVDP7j5QjwQlW9v6yTuwC4RiFJ6vKuJ0lSl0EhSeoyKCRJXQaFJKnLoJAkdf1/k1Yr2NRAyB0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Labeled_data['gender'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf9b64-2831-4b8c-9664-a2f12c9dfd2c",
   "metadata": {},
   "source": [
    "Gender-wise its not too much imabalanced, there seems to be enough data for both genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eac719ba-7e6a-41d3-87c1-0890d35d15fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Labeled_data['height'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13f90058-4e03-4dd6-aefe-4bd4cc87fc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Labeled_data['weight'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ce44fb9-3fe6-460b-bf91-5b7d0516b89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Labeled_data['age'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba086ab1-df29-4208-9b77-468cd48206f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.412865e+06</td>\n",
       "      <td>1.412865e+06</td>\n",
       "      <td>1.412865e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.883202e+01</td>\n",
       "      <td>1.739890e+02</td>\n",
       "      <td>7.212055e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.303463e+00</td>\n",
       "      <td>8.798617e+00</td>\n",
       "      <td>1.598129e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.610000e+02</td>\n",
       "      <td>4.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>1.640000e+02</td>\n",
       "      <td>6.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>1.750000e+02</td>\n",
       "      <td>7.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>1.800000e+02</td>\n",
       "      <td>7.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>1.900000e+02</td>\n",
       "      <td>1.020000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        height        weight\n",
       "count  1.412865e+06  1.412865e+06  1.412865e+06\n",
       "mean   2.883202e+01  1.739890e+02  7.212055e+01\n",
       "std    5.303463e+00  8.798617e+00  1.598129e+01\n",
       "min    1.800000e+01  1.610000e+02  4.800000e+01\n",
       "25%    2.500000e+01  1.640000e+02  6.000000e+01\n",
       "50%    2.800000e+01  1.750000e+02  7.200000e+01\n",
       "75%    3.100000e+01  1.800000e+02  7.800000e+01\n",
       "max    4.600000e+01  1.900000e+02  1.020000e+02"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labeled_data[['age', 'height', 'weight']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5a762-bcd1-4185-b280-db0cd9d68063",
   "metadata": {},
   "source": [
    "Subjects have age ranging from 18 to 46 however most subjects are in the age range of 24-33.\n",
    "\n",
    "Subjects have height ranging from 161cm - 190cm with median height 175cms. However, 2 seperate peaks are visible at 165 cm and at 180cm indicating bi-modality.\n",
    "\n",
    "Weight range of subjects is 48-102kgs with mean and median value of 72kgs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa690bba-8c1b-49c2-add4-b3b646ccbb19",
   "metadata": {},
   "source": [
    "### Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c09625c9-956b-493e-a6fc-a7bd9fbc5cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attitude.roll         0\n",
       "attitude.pitch        0\n",
       "attitude.yaw          0\n",
       "gravity.x             0\n",
       "gravity.y             0\n",
       "gravity.z             0\n",
       "rotationRate.x        0\n",
       "rotationRate.y        0\n",
       "rotationRate.z        0\n",
       "userAcceleration.x    0\n",
       "userAcceleration.y    0\n",
       "userAcceleration.z    0\n",
       "Subject               0\n",
       "Activity              0\n",
       "gender                0\n",
       "weight                0\n",
       "height                0\n",
       "age                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labeled_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f859d61-4968-4ef9-a6c6-b2a761cf1437",
   "metadata": {},
   "source": [
    "There are no missing values in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d93b4b9-6b0f-45f1-a119-bce9a23a1e22",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec7590-236a-41bf-9848-4e21e9ea13ec",
   "metadata": {},
   "source": [
    "Data for all activities for 20 subjects are taken for training dataset and remaining 4 subjects are kept for the test dataset. Data is not split randomly to preserve the sequence of time-series of activities in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e47e0348-778f-44b9-98ed-6674f4974913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1182344, 18)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set= Labeled_data.loc[Labeled_data['Subject'] <= 20]\n",
    "Train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79723da0-27c7-443c-b04c-913709431ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230521, 18)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_set= Labeled_data.loc[Labeled_data['Subject'] > 20]\n",
    "Test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86a5e9a-cf33-4b69-b803-c6ebe0e827ec",
   "metadata": {},
   "source": [
    "## Creating Sliding Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd1d58c-ef5c-433b-9102-6194bf47f655",
   "metadata": {},
   "source": [
    "Sliding window with overlap approach has been used for modelling this time-series activity data. Fixed window length of 100 (meaning subset of 100 rows for each window) with 50% overlap has been selected to construct the window frames. According to available literature this is the most commonly used approach for such data.\n",
    "\n",
    "Sampling rate of the data is not known (it maybe 100Hz or 50Hz). With sampling rate of 100Hz it'll amount to window length of 1 sec and with 50Hz to 2 secs, but in any case window length of such time-frames is considered suitable for such analysis work in the available academic literature. Overlap of 50% will help in reducing the information loss and is also well known industry practice for such time-series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5418744c-3af5-47b5-b2dd-d7573fccec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Sliding Window with 50% overlap\n",
    "def sliding_window(Dataset, win_len):\n",
    "  \n",
    "    offset = int(np.round(win_len * 0.5))\n",
    "    window_num = int((len(Dataset) / offset)-1)\n",
    "    print(window_num)\n",
    "    \n",
    "    New_data = []\n",
    "    for k in range(window_num):\n",
    "        current_set = Dataset[(k*offset): (k*offset + win_len), :]\n",
    "        New_data.append(current_set)\n",
    "    return np.concatenate(New_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e8cea0-c8de-46ea-aad2-aa75bcefc057",
   "metadata": {},
   "source": [
    "## Classification of Activity from the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b72dc8-721f-4624-b9c9-9346fa32b861",
   "metadata": {},
   "source": [
    "### Data Pre-processing for models using all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4ca291f-fdda-46bf-b3c2-506df5eabacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Subject column as it does not add any useful information\n",
    "Train_set_full= Train_set.drop(['Subject'], axis=1)\n",
    "Test_set_full= Test_set.drop(['Subject'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e9387d4-88c7-4801-8eea-e334ef30e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalisation\n",
    "\n",
    "Train_set_full= Train_set_full.to_numpy()  # converting pandas dataframe to numpy array\n",
    "Test_set_full= Test_set_full.to_numpy()\n",
    "\n",
    "# subtracting by mean and dividing by standard deviation of independent variables\n",
    "mean= np.mean(Train_set_full[:,:-5], axis=0)\n",
    "std = np.std(Train_set_full[:,:-5], axis=0)\n",
    "Train_set_full[:,:-5] = (Train_set_full[:,:-5]-mean) / std\n",
    "Test_set_full[:,:-5] = (Test_set_full[:,:-5]-mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0b48ea9-41fd-476d-9431-bfbd650e56cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "win_len = 100\n",
    "features = Train_set_full.shape[1]-5 #minus the label col\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1062db15-6263-4cd6-b4f6-bac020305619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2364500, 17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying to both Train and Test set\n",
    "Train_set_full = sliding_window(Train_set_full, 100)\n",
    "Train_set_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c4e402c-e9bd-4f13-b997-b73e8a69fa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(460900, 17)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_set_full = sliding_window(Test_set_full, 100)\n",
    "Test_set_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2d75814-297b-4fe9-afbb-1828dff0108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting independent variables and Target Variable\n",
    "X_train= Train_set_full[:, :-5]\n",
    "y_train= Train_set_full[:, -5]\n",
    "X_test= Test_set_full[:, :-5]\n",
    "y_test= Test_set_full[:,-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6306aeb7-f84d-4f17-8294-88e6f95bf574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data to convert into window frames\n",
    "X_train = np.reshape(X_train, (-1, win_len, features)) # 3-D array\n",
    "X_test = np.reshape(X_test, (-1, win_len, features))\n",
    "y_train = np.reshape(y_train,(-1, win_len)).astype(int) # 2-D array\n",
    "y_test = np.reshape(y_test,(-1, win_len)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5790bbb-9521-43fb-bd8b-a42fcf640af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting class with maximum counts for each window\n",
    "def max_count(Dataset):\n",
    "    y = np.zeros(len(Dataset))\n",
    "    for i in range(len(Dataset)):\n",
    "        counts = np.bincount(np.reshape(Dataset[i, :], (-1)))\n",
    "        y[i] = np.argmax(counts)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d7be805-3306-45bf-bf70-18acbd1a38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= max_count(y_train)\n",
    "y_test= max_count(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da271881-ec10-431f-8d22-960c881369ef",
   "metadata": {},
   "source": [
    "### Balancing dataset for each activity class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42579e9c-3b56-4700-9bfc-2f3a3bdb0b3a",
   "metadata": {},
   "source": [
    "Since the data was imbabalanced for each activity type, undersampling of majority class technique is applied to balance the different classes of activities before building models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62757700-747f-4a50-9dfd-07630c64327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balanced(X, y, classes, sample_number):\n",
    "    print('each class will have the same sample number')\n",
    "    X_new = np.empty([0, win_len, features])\n",
    "    y_new = np.empty([0])\n",
    "    for i in range(classes):\n",
    "        if len(X[y==i])<sample_number:\n",
    "            print('Error: not enough samples for class '+str(i) +'please choose a smaller number')\n",
    "            break\n",
    "        else:\n",
    "            X_new = np.concatenate((X_new, X[y==i][:sample_number]), axis=0)\n",
    "            print(X_new.shape)\n",
    "        \n",
    "        y_new = np.concatenate((y_new, y[y==i][:sample_number]), axis=0)\n",
    "        print(y_new)\n",
    "    return X_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54998be7-c2f2-4972-a7da-cbd1cfa0e587",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each class will have the same sample number\n",
      "(400, 100, 12)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(800, 100, 12)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "(1200, 100, 12)\n",
      "[0. 0. 0. ... 2. 2. 2.]\n",
      "(1600, 100, 12)\n",
      "[0. 0. 0. ... 3. 3. 3.]\n",
      "(2000, 100, 12)\n",
      "[0. 0. 0. ... 4. 4. 4.]\n",
      "(2400, 100, 12)\n",
      "[0. 0. 0. ... 5. 5. 5.]\n",
      "each class will have the same sample number\n",
      "(200, 100, 12)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(400, 100, 12)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "(600, 100, 12)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "(800, 100, 12)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3.]\n",
      "(1000, 100, 12)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.]\n",
      "(1200, 100, 12)\n",
      "[0. 0. 0. ... 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "classes= 6\n",
    "size_per_class_train = 400\n",
    "size_per_class_test = 200\n",
    "X_train, y_train = Balanced(X_train, y_train, classes, size_per_class_train)\n",
    "X_test, y_test = Balanced(X_test, y_test, classes, size_per_class_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "575b14f4-a752-4ab0-8101-01027c8116f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data back into vectors for classification\n",
    "X_train_copy = np.reshape(X_train, (-1, features*win_len))\n",
    "X_test_copy = np.reshape(X_test, (-1, features*win_len))\n",
    "y_train_copy = y_train.copy()\n",
    "y_test_copy = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b9db748-1098-45d3-946a-a5279fd75262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_copy)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_copy = scaler.transform(X_train_copy)\n",
    "X_test_copy = scaler.transform(X_test_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b79d41-bf40-46f9-952b-2524cae497f7",
   "metadata": {},
   "source": [
    "### Building models using all variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa632598-0ea4-489e-8ea2-cee9a5da0922",
   "metadata": {},
   "source": [
    "Initially various algorithms will be tried with no hyper-parameter tuning to create a baseline and to find out suitable models for further use. Evaluation metrics used throughout is the accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa420e0-f1ba-4f9b-ac53-2689352df6cf",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d11a2e9e-9a72-45d7-914b-fbf5f3d74970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5191666666666667\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver= 'liblinear')\n",
    "clf.fit(X_train_copy, y_train_copy)\n",
    "\n",
    "y_pred_full = clf.predict(X_test_copy)\n",
    "acc_LR_full = accuracy_score(y_test_copy, y_pred_full)\n",
    "print(acc_LR_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7198d8f-3274-409c-80bf-428e00699a1e",
   "metadata": {},
   "source": [
    "Solver lbfgs was not converging hence tried liblinear and it is converging much faster. However accuracy score is not great! Possibly data is not linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b4792-06eb-4323-acbf-91272f72ae45",
   "metadata": {},
   "source": [
    "#### Non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b1c976f-a85e-4789-9bd3-962ebdf87b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6783333333333333\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel=\"rbf\")\n",
    "clf.fit(X_train_copy, y_train_copy)\n",
    "\n",
    "y_pred_full = clf.predict(X_test_copy)\n",
    "acc_SVM_full = accuracy_score(y_test_copy, y_pred_full)\n",
    "print(acc_SVM_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c60d7d-a822-4aed-9b45-1e095a96b344",
   "metadata": {},
   "source": [
    "Better, but still accuracy is low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24379eb-bca0-4296-840f-73fbf24c7780",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e20ee27c-28a5-4128-b8be-b200817b8869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5591666666666667\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_copy, y_train_copy)\n",
    "\n",
    "y_pred_full = clf.predict(X_test_copy)\n",
    "acc_RF_full = accuracy_score(y_test_copy, y_pred_full)\n",
    "print(acc_RF_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35f104-d9bc-4054-b5e1-6e8f52de0278",
   "metadata": {},
   "source": [
    "Tried Bootstrapping algorithm but still very low accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea38ec7-94d7-4f36-9a46-78273e9ea104",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1219f9bb-3351-444a-863d-af745cab259f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:42:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.78\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(use_label_encoder=False)\n",
    "clf.fit(X_train_copy, y_train_copy)\n",
    "\n",
    "y_pred_full = clf.predict(X_test_copy)\n",
    "acc_XGB_full = accuracy_score(y_test_copy, y_pred_full)\n",
    "print(acc_XGB_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf611ab-d14d-43ca-a333-233eae85262f",
   "metadata": {},
   "source": [
    "Tried Boosting algorithm and the accuracy improved quite a bit!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa4185-f1be-4530-8cd3-da63e940a7ff",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85fa960c-ccfb-4c67-a962-bebede07bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4141666666666667\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train_copy, y_train_copy)\n",
    "\n",
    "y_pred_full = clf.predict(X_test_copy)\n",
    "acc_KNN_full = accuracy_score(y_test_copy, y_pred_full)\n",
    "print(acc_KNN_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe9690-a0f4-40ed-b6ef-7b51c5272952",
   "metadata": {},
   "source": [
    "Accuracy score is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "062a9fac-146f-46d8-9d60-b1e35fedc66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Base Model  Accuracy Score\n",
      "0              LR        0.519167\n",
      "1  Non-linear SVM        0.678333\n",
      "2   RF Classifier        0.559167\n",
      "3  XGB Classifier        0.780000\n",
      "4             KNN        0.414167\n"
     ]
    }
   ],
   "source": [
    "# Collating output from all the models\n",
    "Accuracy_full_ML= pd.DataFrame({\"Base Model\": [\"LR\", \"Non-linear SVM\", \"RF Classifier\", \"XGB Classifier\", \"KNN\"],\n",
    "                               \"Accuracy Score\": [acc_LR_full, acc_SVM_full, acc_RF_full, acc_XGB_full, acc_KNN_full]})\n",
    "print(Accuracy_full_ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ec11c-d58b-4c9d-babc-e1f43f5360b7",
   "metadata": {},
   "source": [
    "For base model with all variables and no hyper-parameter tuning the accuracy score has been low but XGBoost and non-linear SVM have been the best amongst all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56c659-bf16-4c40-9e5a-93f6e400c083",
   "metadata": {},
   "source": [
    "### Reducing No. of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ef35c-ab1b-442a-9c19-914140cd545b",
   "metadata": {},
   "source": [
    "From the background knowledge, we can maybe remove gravity data from the input as it may be providing redundant information and adding dimensionality with no gain. Accelerometer data provides information on user imparted acceleration and hence keeping gravity readings as well may not be very useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64210001-5140-4c6e-8b87-29c6f29e4a44",
   "metadata": {},
   "source": [
    "### Building model with reduced variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c2179c-1412-4c8a-b636-345917016e7c",
   "metadata": {},
   "source": [
    "New sets are created using train and test sets from previous section but prior to normalisation as removing more columns will change the mean and standard deviation accordingly. All other data pre-processing steps are repeated on the new reduced sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ca4fb6a-a6c1-46ac-b2fd-71798e894f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Subject and gravity columns as it does not add any useful information\n",
    "Train_set_red= Train_set.drop(['Subject', 'gravity.x', 'gravity.y', 'gravity.z'], axis=1)\n",
    "Test_set_red= Test_set.drop(['Subject', 'gravity.x', 'gravity.y', 'gravity.z'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d150943-cf27-4c58-a8cc-21968091a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalisation\n",
    "Train_set_red= Train_set_red.to_numpy()  # converting pandas dataframe to numpy array\n",
    "Test_set_red= Test_set_red.to_numpy()\n",
    "\n",
    "# subtracting by mean and dividing by standard deviation of independent variables\n",
    "mean= np.mean(Train_set_red[:,:-5], axis=0)\n",
    "std = np.std(Train_set_red[:,:-5], axis=0)\n",
    "Train_set_red[:,:-5] = (Train_set_red[:,:-5]-mean) / std\n",
    "Test_set_red[:,:-5] = (Test_set_red[:,:-5]-mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90f77b25-e991-410f-9b33-9a79dfe0f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "win_len = 100\n",
    "features = Train_set_red.shape[1]-5 #minus the label col\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b099-6728-4d32-953a-3d0d3d9976c8",
   "metadata": {},
   "source": [
    "Now number of features have reduced to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d577c0a-362d-4536-94db-7ac52810e55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2364500, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Sliding Window with 50% overlap for both Train and Test sets\n",
    "Train_set_red = sliding_window(Train_set_red, 100)\n",
    "Train_set_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2e35613-d935-41f7-a66c-fa250a2727eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(460900, 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_set_red = sliding_window(Test_set_red, 100)\n",
    "Test_set_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6aa27778-beeb-4314-b66f-fc2dee0bce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting independent variables and Target Variable\n",
    "X_train_red= Train_set_red[:, :-5]\n",
    "y_train_red= Train_set_red[:, -5]\n",
    "X_test_red= Test_set_red[:, :-5]\n",
    "y_test_red= Test_set_red[:,-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8676a14-2c28-4bec-a961-b287d13a3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data to convert into window frames\n",
    "X_train_red = np.reshape(X_train_red, (-1, win_len, features)) # 3-D array\n",
    "X_test_red = np.reshape(X_test_red, (-1, win_len, features))\n",
    "y_train_red = np.reshape(y_train_red,(-1, win_len)).astype(int) # 2-D array\n",
    "y_test_red = np.reshape(y_test_red,(-1, win_len)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fddf5bc-2758-4811-adc4-15a85fd0caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting activity class with maximum counts for each window\n",
    "y_train_red= max_count(y_train_red)\n",
    "y_test_red= max_count(y_test_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5caadf05-4c20-42d2-b937-020d4681cbae",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each class will have the same sample number\n",
      "(400, 100, 9)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(800, 100, 9)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "(1200, 100, 9)\n",
      "[0. 0. 0. ... 2. 2. 2.]\n",
      "(1600, 100, 9)\n",
      "[0. 0. 0. ... 3. 3. 3.]\n",
      "(2000, 100, 9)\n",
      "[0. 0. 0. ... 4. 4. 4.]\n",
      "(2400, 100, 9)\n",
      "[0. 0. 0. ... 5. 5. 5.]\n",
      "each class will have the same sample number\n",
      "(200, 100, 9)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(400, 100, 9)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "(600, 100, 9)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "(800, 100, 9)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3.]\n",
      "(1000, 100, 9)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.]\n",
      "(1200, 100, 9)\n",
      "[0. 0. 0. ... 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "# Balancing dataset for each activity class\n",
    "classes= 6\n",
    "size_per_class_train = 400\n",
    "size_per_class_test = 200\n",
    "X_train_red, y_train_red = Balanced(X_train_red, y_train_red, classes, size_per_class_train)\n",
    "X_test_red, y_test_red = Balanced(X_test_red, y_test_red, classes, size_per_class_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14512e5a-d1aa-4093-9d36-648d838cf428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data back into vectors for classification\n",
    "X_train_copy_red = np.reshape(X_train_red, (-1, features*win_len))\n",
    "X_test_copy_red = np.reshape(X_test_red, (-1, features*win_len))\n",
    "y_train_copy_red = y_train_red.copy()\n",
    "y_test_copy_red = y_test_red.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81d83020-5067-4f5d-ac8e-85ba8ab4073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_copy_red)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_copy_red = scaler.transform(X_train_copy_red)\n",
    "X_test_copy_red = scaler.transform(X_test_copy_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c095c6ec-ad9c-405f-a115-e0dc18550aea",
   "metadata": {},
   "source": [
    "Trying all the models again on the reduced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d5dab-3295-4a27-805d-3ed075d2efa4",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f706a680-c629-4390-a214-bebfeaee6b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5116666666666667\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver= 'liblinear')\n",
    "clf.fit(X_train_copy_red, y_train_copy_red)\n",
    "\n",
    "y_pred_red = clf.predict(X_test_copy_red)\n",
    "acc_LR_red = accuracy_score(y_test_copy_red, y_pred_red)\n",
    "print(acc_LR_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4964f-74de-4fbd-a12d-485904c40c72",
   "metadata": {},
   "source": [
    "#### Non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8383e446-d823-4e6e-afc4-f5d29ed1a81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7866666666666666\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel=\"rbf\")\n",
    "clf.fit(X_train_copy_red, y_train_copy_red)\n",
    "\n",
    "y_pred_red = clf.predict(X_test_copy_red)\n",
    "acc_SVM_red = accuracy_score(y_test_copy_red, y_pred_red)\n",
    "print(acc_SVM_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0003ab9-4be6-414f-a26f-69dd45f9272c",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e0e4bd7-6b5d-424d-904b-06eab1ebce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5991666666666666\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_copy_red, y_train_copy_red)\n",
    "\n",
    "y_pred_red = clf.predict(X_test_copy_red)\n",
    "acc_RF_red = accuracy_score(y_test_copy_red, y_pred_red)\n",
    "print(acc_RF_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87400206-b28c-4d4c-a8d2-f74dd4af226f",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a8b6bbe-aa84-4de4-ae90-43624b4bb47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:59:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7616666666666667\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(use_label_encoder=False)\n",
    "clf.fit(X_train_copy_red, y_train_copy_red)\n",
    "\n",
    "y_pred_red = clf.predict(X_test_copy_red)\n",
    "acc_XGB_red = accuracy_score(y_test_copy_red, y_pred_red)\n",
    "print(acc_XGB_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a457bf48-0e51-429b-ac9c-bac565c82bc7",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "310bd02d-4ff4-47fd-887f-4f38883d1425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37666666666666665\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train_copy_red, y_train_copy_red)\n",
    "\n",
    "y_pred_red = clf.predict(X_test_copy_red)\n",
    "acc_KNN_red = accuracy_score(y_test_copy_red, y_pred_red)\n",
    "print(acc_KNN_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24facae3-aef7-4e51-8a3f-d974da302b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Reduced Model  Accuracy Score\n",
      "0              LR        0.511667\n",
      "1  Non-linear SVM        0.786667\n",
      "2   RF Classifier        0.599167\n",
      "3  XGB Classifier        0.761667\n",
      "4             KNN        0.376667\n"
     ]
    }
   ],
   "source": [
    "# Collating output from all the models\n",
    "Accuracy_red_ML= pd.DataFrame({\"Reduced Model\": [\"LR\", \"Non-linear SVM\", \"RF Classifier\", \"XGB Classifier\", \"KNN\"],\n",
    "                               \"Accuracy Score\": [acc_LR_red, acc_SVM_red, acc_RF_red, acc_XGB_red, acc_KNN_red]})\n",
    "print(Accuracy_red_ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49308fde-0b59-4989-aefd-09d6eb2d9a53",
   "metadata": {},
   "source": [
    "Accuracy scores improved a little bit from the base models but still are not very high. Non-linear SVM and XGBoost have been performing better in both cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2c5932-002d-40ff-9bf4-4c4c8bee03ce",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ddc2a2-5c14-4486-8376-39a96604f9bd",
   "metadata": {},
   "source": [
    "Can try hyperparameter tuning for non-linear SVM using GridSearchCV if that helps in improving the accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d95c7-3dde-43d8-9367-b0ab5f97be60",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8fbe9cea-803f-4a60-b1a3-9a799a20649d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  12.8s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  12.2s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  13.9s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  14.6s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  12.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   6.6s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   7.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   6.2s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   9.4s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   7.5s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   9.2s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   7.6s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   8.2s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   7.7s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   9.5s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   9.9s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   9.9s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   9.3s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  10.7s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   6.2s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   8.1s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   6.6s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   7.3s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   6.3s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   7.6s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   8.3s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   7.6s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  10.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   9.3s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   8.2s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   9.5s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   9.7s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   7.7s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   9.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   7.4s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   6.9s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   7.1s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   7.7s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   7.3s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   9.6s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   8.1s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   7.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   6.1s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   6.9s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   8.5s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   7.9s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   9.9s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  10.2s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  10.2s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   9.8s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  11.3s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=  10.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   7.7s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   8.3s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   8.3s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   8.9s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  10.9s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  12.2s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  13.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  11.4s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  10.7s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   6.8s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   6.2s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   7.5s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   6.5s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   9.4s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   6.5s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   6.7s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   9.3s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   9.4s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  10.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   9.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   9.7s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   8.4s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   7.4s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   6.5s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   7.3s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   6.4s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   7.1s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   6.6s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   7.1s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   7.6s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   6.6s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   9.2s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.9s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.2s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.8s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   6.8s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   6.5s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   6.4s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   7.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   6.5s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   7.2s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.2s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.7s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   6.5s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   4.8s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.7s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   4.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   4.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   4.3s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  10.9s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  10.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   8.7s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   7.5s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   8.6s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   5.3s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   5.4s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   5.5s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   5.6s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  11.5s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  11.3s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  11.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  10.8s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=  11.7s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   6.7s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   7.1s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   6.5s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   7.2s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   6.3s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  10.1s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  12.5s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   8.9s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   9.7s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   9.4s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   6.7s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   6.5s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   7.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   6.4s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   7.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   6.7s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   7.2s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   7.2s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   7.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   8.2s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   9.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   8.5s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   8.8s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   9.2s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   6.3s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   6.8s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   7.4s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   6.4s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   7.2s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   6.7s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   4.4s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   4.5s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   4.6s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   4.7s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   4.3s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   7.3s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   6.6s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   7.6s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   6.6s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   7.7s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   4.4s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   4.9s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   5.7s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   5.2s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   8.8s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=  11.9s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=  12.1s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=  11.4s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=  12.8s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=  11.0s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   9.2s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   6.6s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   7.2s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   6.4s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   9.8s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   6.7s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   6.7s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   9.3s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   9.8s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   9.5s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   9.1s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   9.9s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   7.4s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   8.1s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   6.5s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   7.2s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   7.3s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   9.5s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   7.6s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   9.1s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=  10.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=  10.7s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   9.8s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=  10.4s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=  10.7s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   6.6s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   7.1s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   6.5s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   7.3s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   9.4s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   7.7s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   6.7s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   8.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   6.5s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   7.4s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   4.8s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   4.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   5.2s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   5.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   4.6s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   7.9s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   6.6s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   9.7s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   7.9s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   9.6s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   5.6s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   5.1s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   6.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   5.2s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   5.2s\n",
      "SVC(C=10, gamma=0.001)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']} # creating parameters dictionary\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train_copy_red, y_train_copy_red)\n",
    "print(grid.best_estimator_) # getting optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16e3c989-869e-4f21-b94f-62ee5ced2070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.001)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refitting onto train set\n",
    "grid.best_estimator_.fit(X_train_copy_red, y_train_copy_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1a7d9d7-1a54-4147-90d6-a9a09eb00cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Predicting on test set\n",
    "y_pred_red_tuned = grid.best_estimator_.predict(X_test_copy_red)\n",
    "acc_SVM_red_tuned = accuracy_score(y_test_copy_red, y_pred_red_tuned)\n",
    "print(acc_SVM_red_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57307ee-181b-4589-8da3-9adff417fa86",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning didn't seemed to improve the accuracy score any further!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b65918-f9da-4466-a462-c688455b4ac5",
   "metadata": {},
   "source": [
    "## Deep Learning Models for classification of Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8853a617-65f7-4b80-8e6d-24d0bfbe0509",
   "metadata": {},
   "source": [
    "Since traditional ML algorithms were giving the accuracy score around 80% and even hyper-parameter tuning does not seem to improve the score further, trying some Deep Learning algorithms- CNN and LSTM both of which are well known for working well on sequential/spatial data. Also they do not need any feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3605e-3564-4775-a6fd-d74137f7d48c",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041cffb4-1121-42b1-b9d0-2f85fece291e",
   "metadata": {},
   "source": [
    "#### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49cd35d4-20cc-426a-a916-1572601a89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting independent variables and Target Variable\n",
    "X_train_CNN= Train_set_red[:, :-5]\n",
    "y_train_CNN= Train_set_red[:, -5]\n",
    "X_test_CNN= Test_set_red[:, :-5]\n",
    "y_test_CNN= Test_set_red[:,-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1b52d6d-5b8e-48a5-89db-4c466278abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data\n",
    "X_train = np.reshape(X_train_CNN, (-1, win_len, features, 1))\n",
    "X_test = np.reshape(X_test_CNN, (-1, win_len, features, 1))\n",
    "y_train = np.reshape(y_train_CNN,(-1, win_len)).astype(int)\n",
    "y_test = np.reshape(y_test_CNN,(-1, win_len)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4dbf8b30-b97b-4e77-a5f7-d1f174591a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= max_count(y_train)\n",
    "y_test= max_count(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "037507a6-b131-4fa0-a214-a16813fdf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for labels\n",
    "classes= 6\n",
    "y_train_copy = keras.utils.np_utils.to_categorical(y_train, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2229a0-b18b-4746-8eef-d9f70b130587",
   "metadata": {},
   "source": [
    "#### Building Base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee8893a-51a3-4f2a-bd2b-ba5b7d8d843f",
   "metadata": {},
   "source": [
    "First I have started with an input layer, pooling layer and a dropout layer followed by flattening and a dense layer. And added another drop out layer before the final output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f5da8db-b9a7-4710-aea2-0a907da1eb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 100, 9, 16)        64        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 100, 4, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 4, 16)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                102416    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,582\n",
      "Trainable params: 102,582\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(16, kernel_size=(1, 3), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e97bac6-9e0d-4667-ace5-3c105d41402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f28b9b6-ce95-4884-bb3c-b603cce203f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "370/370 [==============================] - 49s 98ms/step - loss: 1.0751 - accuracy: 0.6095\n",
      "Epoch 2/3\n",
      "370/370 [==============================] - 39s 105ms/step - loss: 0.8694 - accuracy: 0.6973\n",
      "Epoch 3/3\n",
      "370/370 [==============================] - 39s 106ms/step - loss: 0.7802 - accuracy: 0.7083\n"
     ]
    }
   ],
   "source": [
    "# Fitting CNN model\n",
    "CNN = model.fit(X_train, y_train_copy,\n",
    "            batch_size=64,\n",
    "            epochs=3,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab68e9-7fb2-42d3-a85d-41b8b25f22b1",
   "metadata": {},
   "source": [
    "Accuracy score doesn't look very great!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68575fe3-11af-416b-a3fb-08fc1ab0b59b",
   "metadata": {},
   "source": [
    "#### Adding another set of convolution, pooling and dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7184ecf-a021-4fdc-858e-e12ca9d6a704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 100, 9, 16)        64        \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 100, 4, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 100, 4, 16)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 100, 4, 16)        784       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 100, 2, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100, 2, 16)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                51216     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,166\n",
      "Trainable params: 52,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(16, kernel_size=(1, 3), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(16, kernel_size=(1, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3cb6191-a5c3-4d30-a7a0-fd0294f74de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eafc0008-4eda-4e10-ae48-33c5610c993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "370/370 [==============================] - 58s 149ms/step - loss: 1.1919 - accuracy: 0.5291\n",
      "Epoch 2/3\n",
      "370/370 [==============================] - 57s 155ms/step - loss: 0.9629 - accuracy: 0.6015\n",
      "Epoch 3/3\n",
      "370/370 [==============================] - 58s 156ms/step - loss: 0.9127 - accuracy: 0.6235\n"
     ]
    }
   ],
   "source": [
    "# Fitting CNN model\n",
    "CNN = model.fit(X_train, y_train_copy,\n",
    "            batch_size=64,\n",
    "            epochs=3,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45dd9b-cb12-45f8-8958-4b1560c99d2d",
   "metadata": {},
   "source": [
    "Accuracy score got even lower!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b4ec0-5ba3-484c-b190-a3b4d9788301",
   "metadata": {},
   "source": [
    "#### Adding number of nodes into layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2c691fe-4075-4ce2-bed9-7570309ac71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 100, 9, 32)        128       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 100, 4, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 100, 4, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 100, 4, 32)        3104      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 100, 2, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 100, 2, 32)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                409664    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 413,286\n",
      "Trainable params: 413,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(32, kernel_size=(1, 3), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, kernel_size=(1, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fde42410-1cfc-4dd1-bc4f-1557470462cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc74a4a7-ec41-470c-a408-e784d6c43b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "370/370 [==============================] - 122s 324ms/step - loss: 0.7575 - accuracy: 0.6981\n",
      "Epoch 2/3\n",
      "370/370 [==============================] - 141s 381ms/step - loss: 0.4983 - accuracy: 0.8031\n",
      "Epoch 3/3\n",
      "370/370 [==============================] - 128s 345ms/step - loss: 0.4062 - accuracy: 0.8465\n"
     ]
    }
   ],
   "source": [
    "# Fitting CNN model\n",
    "CNN = model.fit(X_train, y_train_copy,\n",
    "            batch_size=64,\n",
    "            epochs=3,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5962ced-b27e-476b-8c20-bc237e97583a",
   "metadata": {},
   "source": [
    "accuracy score improved quite a bit by increasing the number of nodes in the layers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d15b5-6ba8-412d-ba5b-a9e0d07050b2",
   "metadata": {},
   "source": [
    "#### Increasing batch size and number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b8d74c2-2a01-451a-8d70-71be729a8280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 116s 622ms/step - loss: 0.3609 - accuracy: 0.8690\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 115s 619ms/step - loss: 0.3285 - accuracy: 0.8851\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 115s 623ms/step - loss: 0.3057 - accuracy: 0.8917\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 114s 619ms/step - loss: 0.2918 - accuracy: 0.8988\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 115s 623ms/step - loss: 0.2757 - accuracy: 0.9058\n"
     ]
    }
   ],
   "source": [
    "# Fitting CNN model\n",
    "CNN = model.fit(X_train, y_train_copy,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ae58a-3140-4acf-93da-72e32a224cef",
   "metadata": {},
   "source": [
    "accuracy score further improved by increasing the batch size and number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb1ff0f-3440-49bb-9521-a9a393837131",
   "metadata": {},
   "source": [
    "#### Increasing kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c2eed30c-ed03-4ac9-9a0a-465eed1428ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 100, 9, 32)        192       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 100, 4, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 100, 4, 32)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 100, 4, 32)        5152      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 100, 2, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 100, 2, 32)        0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                409664    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 415,398\n",
      "Trainable params: 415,398\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(32, kernel_size=(1, 5), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, kernel_size=(1, 5), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "18451f47-a20f-4232-a54f-3452c62db03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1dc7677f-cbe2-4e15-a277-11f310296988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 140s 743ms/step - loss: 0.7938 - accuracy: 0.6965\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 135s 731ms/step - loss: 0.4692 - accuracy: 0.8263\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 135s 730ms/step - loss: 0.3709 - accuracy: 0.8675\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 134s 723ms/step - loss: 0.3191 - accuracy: 0.8892\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 135s 728ms/step - loss: 0.2900 - accuracy: 0.9015\n"
     ]
    }
   ],
   "source": [
    "# Fitting CNN model\n",
    "CNN = model.fit(X_train, y_train_copy,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78057c70-459e-4262-ba71-e031795b4eb9",
   "metadata": {},
   "source": [
    "accuracy score increased by increasing the kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36191b0d-0f8d-4e95-b5e4-5a4c742dffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 100, 9, 32)        256       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 100, 4, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 100, 4, 32)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 100, 4, 32)        7200      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 100, 2, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 100, 2, 32)        0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                409664    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 417,510\n",
      "Trainable params: 417,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(32, kernel_size=(1, 7), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, kernel_size=(1, 7), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9203b21a-fd37-4e16-9e44-c61620e86664",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12ced8e0-85f3-4322-ae92-33708a649d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 157s 831ms/step - loss: 0.9433 - accuracy: 0.6233\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 155s 840ms/step - loss: 0.6140 - accuracy: 0.7468\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 155s 838ms/step - loss: 0.5263 - accuracy: 0.7920\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 156s 844ms/step - loss: 0.4772 - accuracy: 0.8068\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 162s 877ms/step - loss: 0.4477 - accuracy: 0.8182\n"
     ]
    }
   ],
   "source": [
    "# Fitting CNN model\n",
    "CNN = model.fit(X_train, y_train_copy,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9924538-b319-4f8a-a77e-465ecb61bed2",
   "metadata": {},
   "source": [
    "accuracy score increased by increasing the kernel_size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c605c9c-2d39-4cfd-a618-8e2aba7854eb",
   "metadata": {},
   "source": [
    "#### Adding another convolution layer after input layer to give it better chance to learn the patterns before pooling and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c64bb982-6c29-4743-916b-1e8e8bffdb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 100, 9, 32)        256       \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 100, 9, 32)        7200      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 100, 4, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 100, 4, 32)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 100, 4, 32)        7200      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 100, 2, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 100, 2, 32)        0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                409664    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 424,710\n",
      "Trainable params: 424,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(32, kernel_size=(1, 7), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(Conv2D(32, kernel_size=(1, 7), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, kernel_size=(1, 7), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11c11cb3-0def-42ab-b22f-7a98b3f17a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9311024-767c-4a52-a995-b4413316bf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 323s 2s/step - loss: 0.8225 - accuracy: 0.6628\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 328s 2s/step - loss: 0.4494 - accuracy: 0.8264\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 309s 2s/step - loss: 0.3722 - accuracy: 0.8659\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 310s 2s/step - loss: 0.3217 - accuracy: 0.8860\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 314s 2s/step - loss: 0.2856 - accuracy: 0.8994\n"
     ]
    }
   ],
   "source": [
    "# Fitting CNN model\n",
    "CNN = model.fit(X_train, y_train_copy,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef91f4a-c6e6-4e43-9c3d-6bfedba2744b",
   "metadata": {},
   "source": [
    "Its observed that adding more layers does not improve accuracy score but adding number of nodes in each layer significantly improves the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd0e20c-3e71-4226-8928-2a3548bc6077",
   "metadata": {},
   "source": [
    "#### Final CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a26c1-2311-4d9d-a116-e40f1c370bc0",
   "metadata": {},
   "source": [
    "Final model has an input layer, then pooling layer followed by a dopout layer. Then another set of convolution, pooling and dropout layer before flattening and then a dense and dropout layer before final output layer. Activation function is relu for all the layers except output layer where it is softmax function. Kernel size selected is 1x7 and padding is kept to be same. 50% dropout is selected and number of filters in each layer is kept as 64. Batch size is kept as 128 and number of Epochs to be 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8b98cb6-42c1-4596-b18c-71c8dc4d8094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 100, 9, 64)        512       \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 100, 4, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 100, 4, 64)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 100, 4, 64)        28736     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 100, 2, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 100, 2, 64)        0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                819264    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 848,902\n",
      "Trainable params: 848,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(64, kernel_size=(1, 7), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, kernel_size=(1, 7), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41d20bf0-20f5-4844-9fdc-f142c18cfb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4318509e-a9a5-4eba-ac4e-57e40e4ba976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 379s 2s/step - loss: 0.7604 - accuracy: 0.7086\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 380s 2s/step - loss: 0.4117 - accuracy: 0.8494\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 374s 2s/step - loss: 0.3581 - accuracy: 0.8747\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 378s 2s/step - loss: 0.3139 - accuracy: 0.8937\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 378s 2s/step - loss: 0.2865 - accuracy: 0.9032\n"
     ]
    }
   ],
   "source": [
    "# Fitting CNN model\n",
    "CNN = model.fit(X_train, y_train_copy,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a96e8-2e37-446e-a5bf-812a5d1c3102",
   "metadata": {},
   "source": [
    "#### Predicting on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33067611-9bf4-4701-855e-95d029269367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8837057930136689\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3707360a-407d-4df1-affb-27ca9be6e492",
   "metadata": {},
   "source": [
    "### Long-Short Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3474c974-7d04-4b6a-98b8-82331acd8d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data\n",
    "X_train = np.reshape(X_train_CNN, (-1, win_len, features))\n",
    "X_test = np.reshape(X_test_CNN, (-1, win_len, features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62688e84-2cb1-4b16-ba4b-118f39921258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 32)           5376      \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 100, 32)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,598\n",
      "Trainable params: 30,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(LSTM(32, input_shape= (win_len, features), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e13a66d3-db86-46e5-90ba-728095da1571",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b744cb03-13f2-4fe5-a6b5-d5d0996bc535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 158s 755ms/step - loss: 0.7506 - accuracy: 0.7441\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 140s 757ms/step - loss: 0.2741 - accuracy: 0.9270\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 139s 749ms/step - loss: 0.2049 - accuracy: 0.9447\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 141s 760ms/step - loss: 0.1990 - accuracy: 0.9515\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 142s 768ms/step - loss: 0.1472 - accuracy: 0.9645\n"
     ]
    }
   ],
   "source": [
    "# Fitting LSTM model\n",
    "LSTM = model.fit(X_train, y_train_copy,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7bb09dfc-5d29-4aa5-8f90-e4dc4c9df1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9318724235192015\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee623bf-e171-4315-8aca-edb9d2819494",
   "metadata": {},
   "source": [
    "The base model gives decent accuracy score and no further hyper-parameter tuning is being considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d99d65-402b-41f7-9cfb-bc5485d47059",
   "metadata": {},
   "source": [
    "### Overall Summary for prediction of activity from available data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e9e26-3659-408e-8400-624f9f681829",
   "metadata": {},
   "source": [
    "Support Vector Classifier, XGBoost Classifier have been found the best amongst the traditional ML algorithms giving an accuracy score around 80%. However DL models have been found to be better performing with CNN giving an accuracy score around 88% and LSTM giving around 93%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7800a9-7bec-4c16-8d7c-e353794d4f13",
   "metadata": {},
   "source": [
    "## Classification of Gender from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90170386-c2e1-45f9-8122-bce21b3ac981",
   "metadata": {},
   "source": [
    "Only reduced dataset with Attitude, Useracceleration and Rotation Rate as input variables will be used and will try all the different models as were used on classification of activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffeb7c3-40c3-4bad-b963-07774c4dfd9e",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6e38035-adec-473c-bd4d-2649b7566a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting independent variables and Target Variable\n",
    "X_train_gender= Train_set_red[:, :-5]\n",
    "y_train_gender= Train_set_red[:, -4]\n",
    "X_test_gender= Test_set_red[:, :-5]\n",
    "y_test_gender= Test_set_red[:,-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6b6564f-1528-48be-a67b-1555fe3e8dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data to convert into window frames\n",
    "X_train_gender = np.reshape(X_train_gender, (-1, win_len, features)) # 3-D array\n",
    "X_test_gender = np.reshape(X_test_gender, (-1, win_len, features))\n",
    "y_train_gender = np.reshape(y_train_gender,(-1, win_len)).astype(int) # 2-D array\n",
    "y_test_gender = np.reshape(y_test_gender,(-1, win_len)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea6557c8-6cb6-4d09-96b5-2ea2ba8c1c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting activity class with maximum counts for each window\n",
    "y_train_gender= max_count(y_train_gender)\n",
    "y_test_gender= max_count(y_test_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "021d64d6-f02e-49a7-905c-fd6dfa40835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data back into vectors for classification\n",
    "X_train_copy_gender = np.reshape(X_train_gender, (-1, features*win_len))\n",
    "X_test_copy_gender = np.reshape(X_test_gender, (-1, features*win_len))\n",
    "y_train_copy_gender = y_train_gender.copy()\n",
    "y_test_copy_gender = y_test_gender.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08c94ab1-023d-4ce4-b7dd-5206ba810c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_copy_gender)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_copy_gender = scaler.transform(X_train_copy_gender)\n",
    "X_test_copy_gender = scaler.transform(X_test_copy_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea02dd-3adf-45ea-8c4c-8073a25b84f5",
   "metadata": {},
   "source": [
    "### Building model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d3b6d-458d-4b92-9994-1e48387407e8",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fb5a49e6-67a1-4ffd-b252-40591f3a4cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6174875244087654\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver= 'liblinear')\n",
    "clf.fit(X_train_copy_gender, y_train_copy_gender)\n",
    "\n",
    "y_pred_gender = clf.predict(X_test_copy_gender)\n",
    "acc_LR_gender = accuracy_score(y_test_copy_gender, y_pred_gender)\n",
    "print(acc_LR_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ad810-48dc-4578-8fa8-0d92145cfb20",
   "metadata": {},
   "source": [
    "Used Liblinear solver here as default lbfgs was failing to converge even with max_iter= 1000. Changing the solver did not changed the accuracy score but only helped in convergence faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532841fb-831e-439a-a1d5-907c85ea3e49",
   "metadata": {},
   "source": [
    "#### Non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d86edcd7-c010-461a-aa29-ca83f9a0fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5458884790627034\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel=\"rbf\")\n",
    "clf.fit(X_train_copy_gender, y_train_copy_gender)\n",
    "\n",
    "y_pred_gender = clf.predict(X_test_copy_gender)\n",
    "acc_SVM_gender = accuracy_score(y_test_copy_gender, y_pred_gender)\n",
    "print(acc_SVM_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec245a9f-b62a-4fa0-8fd3-5ceea95a6da9",
   "metadata": {},
   "source": [
    "accuracy score is only around 55%, which is not great!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741591fa-fe9c-45c6-b181-e8692a16e2e4",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0fcaed41-93d8-4928-9ed9-426496ae7032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:24:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.5378607073117813\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(use_label_encoder=False)\n",
    "clf.fit(X_train_copy_gender, y_train_copy_gender)\n",
    "\n",
    "y_pred_gender = clf.predict(X_test_copy_gender)\n",
    "acc_XGB_gender = accuracy_score(y_test_copy_gender, y_pred_gender)\n",
    "print(acc_XGB_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e127b-0662-4671-99fe-22833f9a1781",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "01875e91-77c2-497d-ad64-1fdb409aa29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5382946409199393\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_copy_gender, y_train_copy_gender)\n",
    "\n",
    "y_pred_gender = clf.predict(X_test_copy_gender)\n",
    "acc_RF_gender = accuracy_score(y_test_copy_gender, y_pred_gender)\n",
    "print(acc_RF_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985a7fa4-d03d-4773-b1f4-9240c829b60b",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f9c28b9e-f0c2-4a96-9499-7a687b09118c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49598611412453897\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train_copy_gender, y_train_copy_gender)\n",
    "\n",
    "y_pred_gender = clf.predict(X_test_copy_gender)\n",
    "acc_KNN_gender = accuracy_score(y_test_copy_gender, y_pred_gender)\n",
    "print(acc_KNN_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3498d46a-928a-465d-a6b5-ae9bf624d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model  Accuracy Score\n",
      "0              LR        0.617488\n",
      "1  Non-linear SVM        0.545888\n",
      "2   RF Classifier        0.538295\n",
      "3  XGB Classifier        0.537861\n",
      "4             KNN        0.495986\n"
     ]
    }
   ],
   "source": [
    "# Collating output from all the models\n",
    "Accuracy_gender_ML= pd.DataFrame({\"Model\": [\"LR\", \"Non-linear SVM\", \"RF Classifier\", \"XGB Classifier\", \"KNN\"],\n",
    "                               \"Accuracy Score\": [acc_LR_gender, acc_SVM_gender, acc_RF_gender, acc_XGB_gender, acc_KNN_gender]})\n",
    "print(Accuracy_gender_ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b05028-0f45-47cf-8f0a-f403f6714b5d",
   "metadata": {},
   "source": [
    "Amongst the traditional ML models without any hyper-parameter tuning, best accuracy score obtained is 62% using Logistic Regression. However, accuracy score is very low, can try tuning it's hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985db653-4f7f-4724-aa27-ec9381833af4",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7135c4c0-cb98-4f39-a30f-fca7318de2f7",
   "metadata": {},
   "source": [
    "Since it was already observed that solver was not helping with improving the accuracy score but only in speed of convergence and lbfgs was taking very long whilst liblinear worked fine, it will be kept constant and different penalty and C values will be tried using GridSearchCV. C values control the penalty strength. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "415d295e-025b-4507-a948-58b54e74581f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time= 1.3min\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=  33.1s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=  38.7s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=  45.9s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=  48.2s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=  50.2s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=  51.2s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time= 1.0min\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=  49.9s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=  56.1s\n",
      "[CV] END ....................................C=1, penalty=l1; total time= 5.4min\n",
      "[CV] END ....................................C=1, penalty=l1; total time=12.8min\n",
      "[CV] END ....................................C=1, penalty=l1; total time= 8.9min\n",
      "[CV] END ....................................C=1, penalty=l1; total time= 7.2min\n",
      "[CV] END ....................................C=1, penalty=l1; total time= 9.3min\n",
      "[CV] END ....................................C=1, penalty=l2; total time= 1.8min\n",
      "[CV] END ....................................C=1, penalty=l2; total time= 2.6min\n",
      "[CV] END ....................................C=1, penalty=l2; total time= 2.1min\n",
      "[CV] END ....................................C=1, penalty=l2; total time= 2.1min\n",
      "[CV] END ....................................C=1, penalty=l2; total time= 2.8min\n",
      "[CV] END ...................................C=10, penalty=l1; total time=45.8min\n",
      "[CV] END ...................................C=10, penalty=l1; total time=77.9min\n",
      "[CV] END ...................................C=10, penalty=l1; total time=57.6min\n",
      "[CV] END ...................................C=10, penalty=l1; total time=41.2min\n",
      "[CV] END ...................................C=10, penalty=l1; total time=71.3min\n",
      "[CV] END ...................................C=10, penalty=l2; total time= 4.5min\n",
      "[CV] END ...................................C=10, penalty=l2; total time= 4.3min\n",
      "[CV] END ...................................C=10, penalty=l2; total time= 4.9min\n",
      "[CV] END ...................................C=10, penalty=l2; total time= 4.7min\n",
      "[CV] END ...................................C=10, penalty=l2; total time= 5.3min\n",
      "[CV] END ..................................C=100, penalty=l1; total time=64.2min\n",
      "[CV] END .................................C=100, penalty=l1; total time=114.7min\n",
      "[CV] END ..................................C=100, penalty=l1; total time=74.9min\n",
      "[CV] END ..................................C=100, penalty=l1; total time=61.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapil\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................................C=100, penalty=l1; total time=90.9min\n",
      "[CV] END ..................................C=100, penalty=l2; total time= 6.2min\n",
      "[CV] END ..................................C=100, penalty=l2; total time= 8.5min\n",
      "[CV] END ..................................C=100, penalty=l2; total time= 5.7min\n",
      "[CV] END ..................................C=100, penalty=l2; total time= 6.9min\n",
      "[CV] END ..................................C=100, penalty=l2; total time= 8.5min\n",
      "LogisticRegression(C=0.1, penalty='l1', solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100], 'penalty': ['l1', 'l2']} # creating parameters dictionary\n",
    "grid = GridSearchCV(LogisticRegression(solver= 'liblinear'),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train_copy_gender, y_train_copy_gender)\n",
    "print(grid.best_estimator_) # getting optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e94d1b21-4c0e-478d-b268-b827dbf34cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refitting onto train set\n",
    "grid.best_estimator_.fit(X_train_copy_gender, y_train_copy_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "04da952e-2ba3-4022-922e-8cc3240498a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6229116945107399\n"
     ]
    }
   ],
   "source": [
    "# Predicting on test set\n",
    "y_pred_gender_tuned = grid.best_estimator_.predict(X_test_copy_gender)\n",
    "acc_LR_gender_tuned = accuracy_score(y_test_copy_gender, y_pred_gender_tuned)\n",
    "print(acc_LR_gender_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed3bf58-3a81-4fc5-99d8-0d0d63f9738c",
   "metadata": {},
   "source": [
    "Optimal parameters identified are C=0.1, penalty= l1 and solver= liblinear however there is no improvement any further in accuracy score by hyper-parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2800245b-4207-4b93-823f-ec1cf01d3500",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "481d0e4e-5250-4735-8b36-cbbaa13975fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for labels\n",
    "classes= 2\n",
    "y_train_LSTM = keras.utils.np_utils.to_categorical(y_train_gender, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02f3a96b-5636-4988-8824-2fdf43a74b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 32)           5376      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 32)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,338\n",
      "Trainable params: 30,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_gender= Sequential()\n",
    "model_gender.add(LSTM(32, input_shape= (win_len, features), return_sequences=True))\n",
    "model_gender.add(Dropout(0.5))\n",
    "model_gender.add(LSTM(64))\n",
    "model_gender.add(Dropout(0.5))\n",
    "model_gender.add(Dense(2, activation='sigmoid'))\n",
    "model_gender.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51f18061-ddd1-461f-933b-a8ce9fc918bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gender.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "601750da-827a-4a5d-a238-aaaa3cb38eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 165s 752ms/step - loss: 0.5147 - accuracy: 0.7302\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 138s 743ms/step - loss: 0.3274 - accuracy: 0.8468\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 135s 728ms/step - loss: 0.2691 - accuracy: 0.8756\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 134s 727ms/step - loss: 0.2736 - accuracy: 0.8741\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 135s 733ms/step - loss: 0.1851 - accuracy: 0.9228\n"
     ]
    }
   ],
   "source": [
    "# Fitting LSTM model\n",
    "LSTM = model_gender.fit(X_train_gender, y_train_LSTM,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf3a7fbf-fefb-42df-b6ef-97c443f25364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5111737904100673\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model_gender.predict(X_test_gender), axis=1)\n",
    "acc = accuracy_score(y_test_gender, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83b33d-ea4a-40ff-8bdb-560ed7196c88",
   "metadata": {},
   "source": [
    "Test accuracy is very low than the training accuracy meaning the model is overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d480a01-e4a7-4072-aff4-c5b0756d25ad",
   "metadata": {},
   "source": [
    "#### Reducing the complexity (hidden layers) to try to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6cda59f-33b6-4249-a5eb-a1814022b16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 100, 32)           5376      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100, 32)           0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 6402      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,778\n",
      "Trainable params: 11,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_gender= Sequential()\n",
    "model_gender.add(LSTM(32, input_shape= (win_len, features), return_sequences=True))\n",
    "model_gender.add(Dropout(0.5))\n",
    "model_gender.add(Flatten())\n",
    "model_gender.add(Dense(2, activation='sigmoid'))\n",
    "model_gender.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19f1a3f4-4c11-41b0-821d-f06ba2f75a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gender.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d2109e1-7308-46a8-81ab-61d8d8716e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 60s 249ms/step - loss: 0.4283 - accuracy: 0.7904\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 47s 256ms/step - loss: 0.2113 - accuracy: 0.9078\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 50s 271ms/step - loss: 0.1488 - accuracy: 0.9371\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 50s 268ms/step - loss: 0.1170 - accuracy: 0.9517\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 48s 261ms/step - loss: 0.0955 - accuracy: 0.9602\n"
     ]
    }
   ],
   "source": [
    "# Fitting LSTM model\n",
    "LSTM = model_gender.fit(X_train_gender, y_train_LSTM,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f9e523c-0126-42e6-8fb2-9cc2fec4106e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5927533087437622\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model_gender.predict(X_test_gender), axis=1)\n",
    "acc = accuracy_score(y_test_gender, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352c0812-7527-46aa-89f1-38e61a91f241",
   "metadata": {},
   "source": [
    "Test accuracy improved a bit but still model is overfitting. Can try to reduce number of nodes as well as number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af12b948-4ddd-4050-8a2f-f03dff766bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 16)           1664      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 16)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 3202      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,866\n",
      "Trainable params: 4,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_gender= Sequential()\n",
    "model_gender.add(LSTM(16, input_shape= (win_len, features), return_sequences=True))\n",
    "model_gender.add(Dropout(0.5))\n",
    "model_gender.add(Flatten())\n",
    "model_gender.add(Dense(2, activation='sigmoid'))\n",
    "model_gender.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "113ebfba-eddc-4319-8062-37c2e7c2ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gender.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0ac98-89a6-47a5-93ce-097baa3be15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 52/185 [=======>......................] - ETA: 16s - loss: 0.0803 - accuracy: 0.9648"
     ]
    }
   ],
   "source": [
    "# Fitting LSTM model\n",
    "LSTM = model_gender.fit(X_train_gender, y_train_LSTM,\n",
    "            batch_size=128,\n",
    "            epochs=3,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a631732-1575-4b0d-8a9d-de9ff7f9482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5623779561727056\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model_gender.predict(X_test_gender), axis=1)\n",
    "acc_LSTM = accuracy_score(y_test_gender, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab0eea-9b38-4404-a5ef-43c9f80339ec",
   "metadata": {},
   "source": [
    "That didn't helped either, still overfitting and not generalising well. Can try CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8fe52-e013-4831-bcf9-b229f4819068",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbbf3d-87ea-4637-9930-4b4bacaf025c",
   "metadata": {},
   "source": [
    "First will try the same architecture as final model from classification of activity but changing activation function for output to sigmoid, number of nodes in output layer to 2 and loss function as binary_cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "82f9771c-3513-4fcf-bb7a-ff1c31fe6808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data\n",
    "X_train_CNN = np.reshape(X_train_gender, (-1, win_len, features, 1))\n",
    "X_test_CNN = np.reshape(X_test_gender, (-1, win_len, features, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "111e2203-2c36-4002-ba21-49c57587a058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 100, 9, 64)        512       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 100, 4, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 100, 4, 64)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 100, 4, 64)        28736     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 100, 2, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 100, 2, 64)        0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                819264    \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 848,642\n",
      "Trainable params: 848,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(64, kernel_size=(1, 7), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, kernel_size=(1, 7), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5f0ab46a-ba95-4f43-82d6-83ee9f0aa17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bb7c5954-260b-4d68-a17a-36c2df616b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 381s 2s/step - loss: 0.5772 - accuracy: 0.6812\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 374s 2s/step - loss: 0.3724 - accuracy: 0.8561\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 410s 2s/step - loss: 0.2932 - accuracy: 0.9037\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 374s 2s/step - loss: 0.2321 - accuracy: 0.9162\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 375s 2s/step - loss: 0.1947 - accuracy: 0.9326\n"
     ]
    }
   ],
   "source": [
    "CNN = model.fit(X_train_CNN, y_train_LSTM,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "86376431-7f30-4748-83d0-3b4c17a21e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5265784334996746\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test_CNN), axis=1)\n",
    "acc = accuracy_score(y_test_gender, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66acaf-5d4b-4ace-852f-4882e0a01e56",
   "metadata": {},
   "source": [
    "Getting the same problem of overfitting. Can try to reduce the complexity of the model by reducing number of epochs, batch size, number of layers and nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b9b88a09-b517-426e-899d-56a98f2f335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 100, 9, 16)        128       \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 100, 4, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 100, 4, 16)        0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 12802     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,930\n",
      "Trainable params: 12,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(16, kernel_size=(1, 7), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8a9b2abd-7eee-4fd8-8ba5-3a6e77679d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fce2c979-af52-4596-afcb-8007cfc1df13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "370/370 [==============================] - 38s 98ms/step - loss: 0.5180 - accuracy: 0.7474\n",
      "Epoch 2/2\n",
      "370/370 [==============================] - 33s 88ms/step - loss: 0.3885 - accuracy: 0.8322\n"
     ]
    }
   ],
   "source": [
    "CNN = model.fit(X_train_CNN, y_train_LSTM,\n",
    "            batch_size=64,\n",
    "            epochs=2,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9eff381d-e01e-4ac1-93cf-6b0ecd108aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5265784334996746\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test_CNN), axis=1)\n",
    "acc_CNN = accuracy_score(y_test_gender, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d3433d-a256-4466-aeab-7c5796513b2c",
   "metadata": {},
   "source": [
    "That didn't helped much either."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a781663-c628-4aee-ade0-bf56736bd3ae",
   "metadata": {},
   "source": [
    "Maybe data for activities like sitting, standing (latent activities) do not add much useful information for gender classification. Can try on subset of data without those activities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c3b0b3-4be3-4c1b-a425-3062dbe60e06",
   "metadata": {},
   "source": [
    "### Without Sitting and Standing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e739a46e-0942-4ec1-a37b-3838b3e50c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638623, 18)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set_gender= Labeled_data[(Labeled_data['Activity'] != 2) & (Labeled_data['Activity'] != 3) & (Labeled_data['Subject'] <= 20)]\n",
    "Train_set_gender.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "740db755-c104-41ff-98a1-93fa4a595c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129037, 18)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_set_gender= Labeled_data[(Labeled_data['Activity'] != 2) & (Labeled_data['Activity'] != 3) & (Labeled_data['Subject'] > 20)]\n",
    "Test_set_gender.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "46e725cf-8efd-4a9f-bf89-3fab3a34907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Subject and gravity columns as it does not add any useful information\n",
    "Train_set_gender= Train_set_gender.drop(['Subject', 'gravity.x', 'gravity.y', 'gravity.z'], axis=1)\n",
    "Test_set_gender= Test_set_gender.drop(['Subject', 'gravity.x', 'gravity.y', 'gravity.z'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "71d4bda2-0617-4861-9441-9dd6734c76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalisation\n",
    "Train_set_gender= Train_set_gender.to_numpy()  # converting pandas dataframe to numpy array\n",
    "Test_set_gender= Test_set_gender.to_numpy()\n",
    "\n",
    "# subtracting by mean and dividing by standard deviation of independent variables\n",
    "mean= np.mean(Train_set_gender[:,:-5], axis=0)\n",
    "std = np.std(Train_set_gender[:,:-5], axis=0)\n",
    "Train_set_gender[:,:-5] = (Train_set_gender[:,:-5]-mean) / std\n",
    "Test_set_gender[:,:-5] = (Test_set_gender[:,:-5]-mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d68660fb-979a-4c9e-af9f-10427dc0390f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "win_len = 100\n",
    "features = Train_set_gender.shape[1]-5 #minus the label col\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "09c18797-d939-45f0-b139-6722d23fe73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1277100, 14)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Sliding Window with 50% overlap for both Train and Test sets\n",
    "Train_set_gender = sliding_window(Train_set_gender, 100)\n",
    "Train_set_gender.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7a3753bc-cf09-4fac-b37f-2a306f6d0571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(257900, 14)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_set_gender = sliding_window(Test_set_gender, 100)\n",
    "Test_set_gender.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7e9afbd7-5334-4151-b476-0669c6749e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting independent variables and Target Variable\n",
    "X_train_gender= Train_set_gender[:, :-5]\n",
    "y_train_gender= Train_set_gender[:, -4]\n",
    "X_test_gender= Test_set_gender[:, :-5]\n",
    "y_test_gender= Test_set_gender[:,-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bedd4e4e-ce4e-4cb8-b546-fd6261740a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data to convert into window frames\n",
    "X_train_gender = np.reshape(X_train_gender, (-1, win_len, features)) # 3-D array\n",
    "X_test_gender = np.reshape(X_test_gender, (-1, win_len, features))\n",
    "y_train_gender = np.reshape(y_train_gender,(-1, win_len)).astype(int) # 2-D array\n",
    "y_test_gender = np.reshape(y_test_gender,(-1, win_len)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e581e63c-bed8-4bc9-9d63-d992417d0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting activity class with maximum counts for each window\n",
    "y_train_gender= max_count(y_train_gender)\n",
    "y_test_gender= max_count(y_test_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7946a513-d977-44a1-91ff-1bc9e602d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data back into vectors for classification\n",
    "X_train_copy_gender = np.reshape(X_train_gender, (-1, features*win_len))\n",
    "X_test_copy_gender = np.reshape(X_test_gender, (-1, features*win_len))\n",
    "y_train_copy_gender = y_train_gender.copy()\n",
    "y_test_copy_gender = y_test_gender.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1ce307ac-b8b2-4efd-aab5-298479188f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_copy_gender)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_copy_gender = scaler.transform(X_train_copy_gender)\n",
    "X_test_copy_gender = scaler.transform(X_test_copy_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ce224-d6b0-4aee-8bd7-e6f74e1f876d",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "096468b6-b1db-47e9-aaca-361cb723240e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5250096936797208\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver= 'liblinear')\n",
    "clf.fit(X_train_copy_gender, y_train_copy_gender)\n",
    "\n",
    "y_pred_gender = clf.predict(X_test_copy_gender)\n",
    "acc_LR_gender = accuracy_score(y_test_copy_gender, y_pred_gender)\n",
    "print(acc_LR_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c92546-ca8e-4f28-a13d-e0cf49eec621",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "feefd8df-1d9a-42b9-865e-0b4b9ba2fcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5370298565335402\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_copy_gender, y_train_copy_gender)\n",
    "\n",
    "y_pred_gender = clf.predict(X_test_copy_gender)\n",
    "acc_RF_gender = accuracy_score(y_test_copy_gender, y_pred_gender)\n",
    "print(acc_RF_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e924e39-69ae-4231-a4fc-74a8caaa490d",
   "metadata": {},
   "source": [
    "It didn't helped either in improving the test accuracy and hence will not be trying other models on this reduced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a013f58-b766-4605-8f21-f09d9eddc7e8",
   "metadata": {},
   "source": [
    "#### Overall Summary of Prediction of Gender from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d3257-5b3c-4058-b10f-3ce4456a87b3",
   "metadata": {},
   "source": [
    "Overall Logistic Regression has been found to be having the highest prediction accuracy score of around 62% amongst all the models tried. Reducing the data from certain activities like sitting and standing further reduces the performance and is not useful. Deep Learning models tried are observed to be having overfitting issues which is not improving even with reduction in complexity of models. Hyper-parameter tuning for Logistic regression didn't help either in increasing the test accuracy score any further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e7ca1-6acf-4fa5-ac19-5570a702dd68",
   "metadata": {},
   "source": [
    "## Classification of age from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "231c9839-9868-461d-80c5-42355b953230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting independent variables and Target Variable\n",
    "X_train_age= Train_set_red[:, :-5]\n",
    "y_train_age= Train_set_red[:, -1]\n",
    "X_test_age= Test_set_red[:, :-5]\n",
    "y_test_age= Test_set_red[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b2da4a14-b921-4a7c-9842-1d3e8e236ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting age to categorical\n",
    "y_train_age_cat= np.digitize(y_train_age, bins=[20,30,40])\n",
    "y_test_age_cat= np.digitize(y_test_age, bins=[20,30,40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9b1613f8-407c-4792-a5c6-c71749edf072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data to convert into window frames\n",
    "X_train_age = np.reshape(X_train_age, (-1, win_len, features)) # 3-D array\n",
    "X_test_age = np.reshape(X_test_age, (-1, win_len, features))\n",
    "y_train_age = np.reshape(y_train_age_cat,(-1, win_len)).astype(int) # 2-D array\n",
    "y_test_age = np.reshape(y_test_age_cat,(-1, win_len)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "aa80fdb5-0ec6-468b-ac89-e047ce492e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting target variable class with maximum counts for each window\n",
    "y_train_age= max_count(y_train_age)\n",
    "y_test_age= max_count(y_test_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "746fb0c1-dd2a-4af6-9db2-df35ca57c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data back into vectors for classification\n",
    "X_train_copy_age = np.reshape(X_train_age, (-1, features*win_len))\n",
    "X_test_copy_age = np.reshape(X_test_age, (-1, features*win_len))\n",
    "y_train_copy_age = y_train_age.copy()\n",
    "y_test_copy_age = y_test_age.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b523150b-98f3-4888-8eb5-450b476d89c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_copy_age)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_copy_age = scaler.transform(X_train_copy_age)\n",
    "X_test_copy_age = scaler.transform(X_test_copy_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739407ee-c36d-434f-9bec-ece99b660fdc",
   "metadata": {},
   "source": [
    "#### Logitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a9087ada-4e16-4b27-82b9-c681b50d4fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4623562594922977\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver= 'liblinear')\n",
    "clf.fit(X_train_copy_age, y_train_copy_age)\n",
    "\n",
    "y_pred_age = clf.predict(X_test_copy_age)\n",
    "acc_LR_age = accuracy_score(y_test_copy_age, y_pred_age)\n",
    "print(acc_LR_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab74c7-2ec5-4833-87a9-00900f5478a0",
   "metadata": {},
   "source": [
    "#### Non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dd793b09-ad77-4e83-9cd2-c09921e06315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47667606856151007\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel=\"rbf\")\n",
    "clf.fit(X_train_copy_age, y_train_copy_age)\n",
    "\n",
    "y_pred_age = clf.predict(X_test_copy_age)\n",
    "acc_SVM_age = accuracy_score(y_test_copy_age, y_pred_age)\n",
    "print(acc_SVM_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa81026-97fe-4559-a34a-a0152c205bda",
   "metadata": {},
   "source": [
    "Prediction accuracy is not great."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51533008-2b89-4846-bc25-70f3aa338cbb",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4f116dd6-09ef-40a5-9fc6-b387e5c181ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40919939249294857\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_copy_age, y_train_copy_age)\n",
    "\n",
    "y_pred_age = clf.predict(X_test_copy_age)\n",
    "acc_RF_age = accuracy_score(y_test_copy_age, y_pred_age)\n",
    "print(acc_RF_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122de5e1-18e4-42a6-afc6-a61fd1cceadb",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d9fab149-11f7-4a5d-8562-1b6fe02b9ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5074853547407246\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train_copy_age, y_train_copy_age)\n",
    "\n",
    "y_pred_age = clf.predict(X_test_copy_age)\n",
    "acc_KNN_age = accuracy_score(y_test_copy_age, y_pred_age)\n",
    "print(acc_KNN_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60970f63-d771-4717-8691-5f10213a000d",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9d9afec9-52ce-473c-a2c5-85fdb069acd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapil\\anaconda3\\envs\\Tensor_keras\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:34:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.4163592970275548\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier()\n",
    "clf.fit(X_train_copy_age, y_train_copy_age)\n",
    "\n",
    "y_pred_age = clf.predict(X_test_copy_age)\n",
    "acc_XGB_age = accuracy_score(y_test_copy_age, y_pred_age)\n",
    "print(acc_XGB_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ee305-23e7-4d43-8463-43d1cc9fef14",
   "metadata": {},
   "source": [
    "Even though bins for the label (age) is created as 0,1,2,3, there is no class 0 (age <20 years) present in the training data and hence XGB Classifier is giving error with use of label_encoder= False in the settings. The warning that use of label encoder in future will be deprecated and hence before running this code in future, solution to working without use of label encoder will needed to be considered for such a use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "32f71157-f949-46ad-8757-5dba62dda015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model  Accuracy Score\n",
      "0              LR        0.462356\n",
      "1  Non-linear SVM        0.476676\n",
      "2   RF Classifier        0.409199\n",
      "3             KNN        0.376667\n",
      "4  XGB Classifier        0.416359\n"
     ]
    }
   ],
   "source": [
    "# Collating output from all models\n",
    "Accuracy_age_ML= pd.DataFrame({\"Model\": [\"LR\", \"Non-linear SVM\", \"RF Classifier\", \"KNN\", \"XGB Classifier\"],\n",
    "                               \"Accuracy Score\": [acc_LR_age, acc_SVM_age, acc_RF_age, acc_KNN_age, acc_XGB_age]})\n",
    "print(Accuracy_age_ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d31f9e2-b6f8-40cf-972b-dba3824f8acc",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "56a10b10-5113-4802-88ea-fa1fb425d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for labels\n",
    "classes= 4\n",
    "y_train_LSTM = keras.utils.np_utils.to_categorical(y_train_age, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "195051d0-8447-4076-a10d-fe45c8390157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 100, 32)           5376      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 100, 32)           0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 12804     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,180\n",
      "Trainable params: 18,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_age= Sequential()\n",
    "model_age.add(LSTM(32, input_shape= (win_len, features), return_sequences=True))\n",
    "model_age.add(Dropout(0.5))\n",
    "model_age.add(Flatten())\n",
    "model_age.add(Dense(4, activation='softmax'))\n",
    "model_age.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "13f2f0de-67b8-4836-83f2-ed8b9287d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_age.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d5a30358-7f5d-4209-b6a8-54004dad6c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "185/185 [==============================] - 56s 251ms/step - loss: 0.7357 - accuracy: 0.6548\n",
      "Epoch 2/2\n",
      "185/185 [==============================] - 49s 268ms/step - loss: 0.4616 - accuracy: 0.7962\n"
     ]
    }
   ],
   "source": [
    "# Fitting LSTM model\n",
    "LSTM = model_age.fit(X_train_age, y_train_LSTM,\n",
    "            batch_size=128,\n",
    "            epochs=2,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1756f07f-ed92-48d0-ba79-81941ea61ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41917986548058145\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model_age.predict(X_test_age), axis=1)\n",
    "acc = accuracy_score(y_test_age, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a133a69-0921-44dc-920a-cbc8fd42ae71",
   "metadata": {},
   "source": [
    "Model is overfitting and is not generalising well. Can try CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c2b4f6-63b8-4d82-8ef3-5881e37a7ab4",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c3ea7dd1-25c5-48d0-bfc9-88e24fb6f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data\n",
    "X_train = np.reshape(X_train_age, (-1, win_len, features, 1))\n",
    "X_test = np.reshape(X_test_age, (-1, win_len, features, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "72ed301a-45b2-4fcd-bde6-831ec083cb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 100, 9, 16)        128       \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 100, 4, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 100, 4, 16)        0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 4)                 25604     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,732\n",
      "Trainable params: 25,732\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(16, kernel_size=(1, 7), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2f111d9f-f51c-43bf-86b6-c7511ac2171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f3dcef9f-5f83-4a9d-8c66-e0f883c1faba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 37s 187ms/step - loss: 0.7968 - accuracy: 0.6234s\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 34s 185ms/step - loss: 0.6778 - accuracy: 0.6946\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 34s 184ms/step - loss: 0.6257 - accuracy: 0.7232\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 34s 182ms/step - loss: 0.5981 - accuracy: 0.7331\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 34s 186ms/step - loss: 0.5796 - accuracy: 0.7432\n"
     ]
    }
   ],
   "source": [
    "# Fitting model\n",
    "CNN = model.fit(X_train, y_train_LSTM,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ad0ec95c-75da-47e4-ab6a-3be287060ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49403341288782815\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "acc = accuracy_score(y_test_age, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e27074-cd4e-446a-90b4-599669f5767b",
   "metadata": {},
   "source": [
    "Having similar issues of overfitting with low prediction accuracy score. Can try with balancing the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb0af9-6285-472b-a125-d0b8c1479ca0",
   "metadata": {},
   "source": [
    "#### Balancing each class using SMOTE technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb1223-4dcc-4795-aadb-5f7daf8cfba2",
   "metadata": {},
   "source": [
    "There is high imbalance in the data as most of the subjects are in the age range 24-33 and only few are below 20 or above 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f9aef909-9a09-442d-8f2c-7516842a8688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3], dtype=int64),\n",
       " array([1330776,  909150,  124574], dtype=int64))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_age_cat, return_counts= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "812422a7-c22a-478c-bd4f-998663ad1c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int64), array([101918, 246926, 112056], dtype=int64))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_age_cat, return_counts= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c72123-8c4d-4afa-bdc6-f7d80374eb78",
   "metadata": {},
   "source": [
    "age category 0 (<20) is not present in the training dataset, this can cause issues with classification in that age group. Can try to balance classes using SMOTE technique before modelling. Since it's not possible to do it directly in array, first will create age categories into labelled dataset before using SMOTE on it and then splitting into test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1bd2d4e-d62c-4c2d-a5f4-d9cd1ce94736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude.roll</th>\n",
       "      <th>attitude.pitch</th>\n",
       "      <th>attitude.yaw</th>\n",
       "      <th>gravity.x</th>\n",
       "      <th>gravity.y</th>\n",
       "      <th>gravity.z</th>\n",
       "      <th>rotationRate.x</th>\n",
       "      <th>rotationRate.y</th>\n",
       "      <th>rotationRate.z</th>\n",
       "      <th>userAcceleration.x</th>\n",
       "      <th>userAcceleration.y</th>\n",
       "      <th>userAcceleration.z</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Activity</th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.528132</td>\n",
       "      <td>-0.733896</td>\n",
       "      <td>0.696372</td>\n",
       "      <td>0.741895</td>\n",
       "      <td>0.669768</td>\n",
       "      <td>-0.031672</td>\n",
       "      <td>0.316738</td>\n",
       "      <td>0.778180</td>\n",
       "      <td>1.082764</td>\n",
       "      <td>0.294894</td>\n",
       "      <td>-0.184493</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.527992</td>\n",
       "      <td>-0.716987</td>\n",
       "      <td>0.677762</td>\n",
       "      <td>0.753099</td>\n",
       "      <td>0.657116</td>\n",
       "      <td>-0.032255</td>\n",
       "      <td>0.842032</td>\n",
       "      <td>0.424446</td>\n",
       "      <td>0.643574</td>\n",
       "      <td>0.219405</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>0.114866</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.527765</td>\n",
       "      <td>-0.706999</td>\n",
       "      <td>0.670951</td>\n",
       "      <td>0.759611</td>\n",
       "      <td>0.649555</td>\n",
       "      <td>-0.032707</td>\n",
       "      <td>-0.138143</td>\n",
       "      <td>-0.040741</td>\n",
       "      <td>0.343563</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.134701</td>\n",
       "      <td>-0.167808</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.516768</td>\n",
       "      <td>-0.704678</td>\n",
       "      <td>0.675735</td>\n",
       "      <td>0.760709</td>\n",
       "      <td>0.647788</td>\n",
       "      <td>-0.041140</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>-1.048717</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>-0.008389</td>\n",
       "      <td>0.136788</td>\n",
       "      <td>0.094958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493941</td>\n",
       "      <td>-0.703918</td>\n",
       "      <td>0.672994</td>\n",
       "      <td>0.760062</td>\n",
       "      <td>0.647210</td>\n",
       "      <td>-0.058530</td>\n",
       "      <td>0.114253</td>\n",
       "      <td>-0.912890</td>\n",
       "      <td>0.047341</td>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.353996</td>\n",
       "      <td>-0.044299</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attitude.roll  attitude.pitch  attitude.yaw  gravity.x  gravity.y  \\\n",
       "0       1.528132       -0.733896      0.696372   0.741895   0.669768   \n",
       "1       1.527992       -0.716987      0.677762   0.753099   0.657116   \n",
       "2       1.527765       -0.706999      0.670951   0.759611   0.649555   \n",
       "3       1.516768       -0.704678      0.675735   0.760709   0.647788   \n",
       "4       1.493941       -0.703918      0.672994   0.760062   0.647210   \n",
       "\n",
       "   gravity.z  rotationRate.x  rotationRate.y  rotationRate.z  \\\n",
       "0  -0.031672        0.316738        0.778180        1.082764   \n",
       "1  -0.032255        0.842032        0.424446        0.643574   \n",
       "2  -0.032707       -0.138143       -0.040741        0.343563   \n",
       "3  -0.041140       -0.025005       -1.048717        0.035860   \n",
       "4  -0.058530        0.114253       -0.912890        0.047341   \n",
       "\n",
       "   userAcceleration.x  userAcceleration.y  userAcceleration.z  Subject  \\\n",
       "0            0.294894           -0.184493            0.377542        1   \n",
       "1            0.219405            0.035846            0.114866        1   \n",
       "2            0.010714            0.134701           -0.167808        1   \n",
       "3           -0.008389            0.136788            0.094958        1   \n",
       "4            0.199441            0.353996           -0.044299        1   \n",
       "\n",
       "   Activity  gender  weight  height  age age_group  \n",
       "0         0       1     102     188   46         3  \n",
       "1         0       1     102     188   46         3  \n",
       "2         0       1     102     188   46         3  \n",
       "3         0       1     102     188   46         3  \n",
       "4         0       1     102     188   46         3  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating age categories and labelled dataset\n",
    "age_cat= pd.cut(Labeled_data.age, bins= [0,20,30,40,120], labels= [0, 1, 2, 3])\n",
    "age_cat = age_cat.to_frame()\n",
    "age_cat.columns = ['age_group']\n",
    "New_data = pd.concat([Labeled_data,age_cat],axis = 1)\n",
    "New_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b73c3b59-72a3-49b8-a0b9-57d6d2ce00ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    850152\n",
       "2    449396\n",
       "3     62312\n",
       "0     51005\n",
       "Name: age_group, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_data.drop('age', axis=1, inplace= True)\n",
    "New_data.age_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d00d50d9-29a6-4039-8202-693ceae4404c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    850152\n",
       "1    850152\n",
       "2    850152\n",
       "3    850152\n",
       "Name: age_group, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE for minority classes\n",
    "X_age= New_data.iloc[:, :-5]\n",
    "y_age= New_data.iloc[:, -1]\n",
    "oversample= SMOTE()\n",
    "X_bal_age, y_bal_age= oversample.fit_resample(X_age, y_age)\n",
    "y_bal_age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8da25904-9778-481a-bac2-f2f25e7eaccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3400608, 14)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining X & y to create balanced dataset\n",
    "Bal_data_age = pd.concat([X_bal_age,y_bal_age],axis = 1)\n",
    "Bal_data_age.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed298902-3666-45df-8817-3dc6485c6ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude.roll</th>\n",
       "      <th>attitude.pitch</th>\n",
       "      <th>attitude.yaw</th>\n",
       "      <th>gravity.x</th>\n",
       "      <th>gravity.y</th>\n",
       "      <th>gravity.z</th>\n",
       "      <th>rotationRate.x</th>\n",
       "      <th>rotationRate.y</th>\n",
       "      <th>rotationRate.z</th>\n",
       "      <th>userAcceleration.x</th>\n",
       "      <th>userAcceleration.y</th>\n",
       "      <th>userAcceleration.z</th>\n",
       "      <th>Subject</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.528132</td>\n",
       "      <td>-0.733896</td>\n",
       "      <td>0.696372</td>\n",
       "      <td>0.741895</td>\n",
       "      <td>0.669768</td>\n",
       "      <td>-0.031672</td>\n",
       "      <td>0.316738</td>\n",
       "      <td>0.778180</td>\n",
       "      <td>1.082764</td>\n",
       "      <td>0.294894</td>\n",
       "      <td>-0.184493</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.527992</td>\n",
       "      <td>-0.716987</td>\n",
       "      <td>0.677762</td>\n",
       "      <td>0.753099</td>\n",
       "      <td>0.657116</td>\n",
       "      <td>-0.032255</td>\n",
       "      <td>0.842032</td>\n",
       "      <td>0.424446</td>\n",
       "      <td>0.643574</td>\n",
       "      <td>0.219405</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>0.114866</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.527765</td>\n",
       "      <td>-0.706999</td>\n",
       "      <td>0.670951</td>\n",
       "      <td>0.759611</td>\n",
       "      <td>0.649555</td>\n",
       "      <td>-0.032707</td>\n",
       "      <td>-0.138143</td>\n",
       "      <td>-0.040741</td>\n",
       "      <td>0.343563</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.134701</td>\n",
       "      <td>-0.167808</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.516768</td>\n",
       "      <td>-0.704678</td>\n",
       "      <td>0.675735</td>\n",
       "      <td>0.760709</td>\n",
       "      <td>0.647788</td>\n",
       "      <td>-0.041140</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>-1.048717</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>-0.008389</td>\n",
       "      <td>0.136788</td>\n",
       "      <td>0.094958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493941</td>\n",
       "      <td>-0.703918</td>\n",
       "      <td>0.672994</td>\n",
       "      <td>0.760062</td>\n",
       "      <td>0.647210</td>\n",
       "      <td>-0.058530</td>\n",
       "      <td>0.114253</td>\n",
       "      <td>-0.912890</td>\n",
       "      <td>0.047341</td>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.353996</td>\n",
       "      <td>-0.044299</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attitude.roll  attitude.pitch  attitude.yaw  gravity.x  gravity.y  \\\n",
       "0       1.528132       -0.733896      0.696372   0.741895   0.669768   \n",
       "1       1.527992       -0.716987      0.677762   0.753099   0.657116   \n",
       "2       1.527765       -0.706999      0.670951   0.759611   0.649555   \n",
       "3       1.516768       -0.704678      0.675735   0.760709   0.647788   \n",
       "4       1.493941       -0.703918      0.672994   0.760062   0.647210   \n",
       "\n",
       "   gravity.z  rotationRate.x  rotationRate.y  rotationRate.z  \\\n",
       "0  -0.031672        0.316738        0.778180        1.082764   \n",
       "1  -0.032255        0.842032        0.424446        0.643574   \n",
       "2  -0.032707       -0.138143       -0.040741        0.343563   \n",
       "3  -0.041140       -0.025005       -1.048717        0.035860   \n",
       "4  -0.058530        0.114253       -0.912890        0.047341   \n",
       "\n",
       "   userAcceleration.x  userAcceleration.y  userAcceleration.z  Subject  \\\n",
       "0            0.294894           -0.184493            0.377542        1   \n",
       "1            0.219405            0.035846            0.114866        1   \n",
       "2            0.010714            0.134701           -0.167808        1   \n",
       "3           -0.008389            0.136788            0.094958        1   \n",
       "4            0.199441            0.353996           -0.044299        1   \n",
       "\n",
       "  age_group  \n",
       "0         3  \n",
       "1         3  \n",
       "2         3  \n",
       "3         3  \n",
       "4         3  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bal_data_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81538745-b225-4464-adda-0548aa85b08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2320941, 14)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-test split\n",
    "Age_Train= Bal_data_age.loc[Bal_data_age['Subject'] <= 20]\n",
    "Age_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd51827e-15b2-4eb2-816a-f04d5e00c00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1079667, 14)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Age_Test= Bal_data_age.loc[Bal_data_age['Subject'] > 20]\n",
    "Age_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07ae1afa-4d5e-44e3-b830-876cdd421092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Subject column as it does not add any useful information\n",
    "Age_Train= Age_Train.drop(['Subject', 'gravity.x', 'gravity.y', 'gravity.z'], axis=1)\n",
    "Age_Test= Age_Test.drop(['Subject', 'gravity.x', 'gravity.y', 'gravity.z'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9585577a-7c4f-403e-bfd1-54d0eedf36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalisation\n",
    "Age_Train= Age_Train.to_numpy()  # converting pandas dataframe to numpy array\n",
    "Age_Test= Age_Test.to_numpy()\n",
    "\n",
    "# subtracting by mean and dividing by standard deviation of independent variables\n",
    "mean= np.mean(Age_Train[:,:-1], axis=0)\n",
    "std = np.std(Age_Train[:,:-1], axis=0)\n",
    "Age_Train[:,:-1] = (Age_Train[:,:-1]-mean) / std\n",
    "Age_Test[:,:-1] = (Age_Test[:,:-1]-mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac120ba1-d7af-4c70-a25b-9b67cef5fb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "win_len = 100\n",
    "features = Age_Train.shape[1]-1 #minus the label col\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55756cec-5cf0-4548-b225-3e1b7435e3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4641700, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Sliding Window with 50% overlap\n",
    "Age_Train = sliding_window(Age_Train, 100)\n",
    "Age_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd4bc0f9-2267-4df9-a362-c85327a1ab8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2159200, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Age_Test = sliding_window(Age_Test, 100)\n",
    "Age_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "827dfb78-9568-472f-91a4-415827d236e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting independent variables and Target Variable\n",
    "X_train_age= Age_Train[:, :-1]\n",
    "y_train_age= Age_Train[:, -1]\n",
    "X_test_age= Age_Test[:, :-1]\n",
    "y_test_age= Age_Test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9b2b482-1f7c-426b-9f97-d7ead26d5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data to convert into window frames\n",
    "X_train_age = np.reshape(X_train_age, (-1, win_len, features)) # 3-D array\n",
    "X_test_age = np.reshape(X_test_age, (-1, win_len, features))\n",
    "y_train_age = np.reshape(y_train_age,(-1, win_len)).astype(int) # 2-D array\n",
    "y_test_age = np.reshape(y_test_age,(-1, win_len)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31f37459-66b9-4981-b5e6-97a40a2edd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting target variable class with maximum counts for each window\n",
    "y_train_age= max_count(y_train_age)\n",
    "y_test_age= max_count(y_test_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec27e97c-76d3-4dd1-94e1-e683f57777ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data back into vectors for classification\n",
    "X_train_copy_age = np.reshape(X_train_age, (-1, features*win_len))\n",
    "X_test_copy_age = np.reshape(X_test_age, (-1, features*win_len))\n",
    "y_train_copy_age = y_train_age.copy()\n",
    "y_test_copy_age = y_test_age.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "394c4ae7-9071-40f7-9d87-c83eb37fc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_copy_age)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_copy_age = scaler.transform(X_train_copy_age)\n",
    "X_test_copy_age = scaler.transform(X_test_copy_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e9ae3a-7b8d-4129-a3f8-5712597c39af",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "26aafecf-78b5-4987-8480-4af63ef72a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06139090951211602\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_copy_age, y_train_copy_age)\n",
    "\n",
    "y_pred_age = clf.predict(X_test_copy_age)\n",
    "acc_LR_age = accuracy_score(y_test_copy_age, y_pred_age)\n",
    "print(acc_LR_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8aa8ff-66c8-447d-bdf3-f8e6f104307d",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "82830403-4cd9-48c3-a734-aebadbced2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07714404855673447\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_copy_age, y_train_copy_age)\n",
    "\n",
    "y_pred_age = clf.predict(X_test_copy_age)\n",
    "acc_RF_age = accuracy_score(y_test_copy_age, y_pred_age)\n",
    "print(acc_RF_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a981a12-306a-467a-9ae9-557e39049b3e",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16594dec-7cae-4d2b-84e1-11094eda9ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11156909966654316\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train_copy_age, y_train_copy_age)\n",
    "\n",
    "y_pred_age = clf.predict(X_test_copy_age)\n",
    "acc_KNN_age = accuracy_score(y_test_copy_age, y_pred_age)\n",
    "print(acc_KNN_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1024cc6-fd12-4ed4-9b33-dec06859c764",
   "metadata": {},
   "source": [
    "Balancing of classes using SMOTE technique has worsened the prediction accuracy. Not sure what is causing the accuracy score to drop so much but no other models were further tried as it was not helping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c80c84-502c-499f-81f8-37db6bb6e4aa",
   "metadata": {},
   "source": [
    "#### Overall summary for Classification of Age from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf276583-ebb3-4410-a22c-d6dfc92c16ca",
   "metadata": {},
   "source": [
    "Prediction accuracy score has been obtained very low across most of the models used. KNN has been found to be with highest score but that is very low as well.\n",
    "DL models have been noted to be suffering from over-fitting issue. Using SMOTE technique for balancing the classes drastically reduced the prediction performance of most of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565771d7-f373-41c2-85ee-68970a725340",
   "metadata": {},
   "source": [
    "## Prediction of Subject's Height from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92382974-b445-41ea-8708-5ebf9fb5e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting independent variables and Target Variable\n",
    "X_train_ht= Train_set_red[:, :-5]\n",
    "y_train_ht= Train_set_red[:, -2]\n",
    "X_test_ht= Test_set_red[:, :-5]\n",
    "y_test_ht= Test_set_red[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e430b93-e43e-4c31-acaa-66abcb4b030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data to convert into window frames\n",
    "X_train_ht = np.reshape(X_train_ht, (-1, win_len, features)) # 3-D array\n",
    "X_test_ht = np.reshape(X_test_ht, (-1, win_len, features))\n",
    "y_train_ht = np.reshape(y_train_ht,(-1, win_len)).astype(int) # 2-D array\n",
    "y_test_ht = np.reshape(y_test_ht,(-1, win_len)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "520a712f-d6fe-4a62-b4b1-72a0290ffc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting activity class with maximum counts for each window\n",
    "y_train_ht= max_count(y_train_ht)\n",
    "y_test_ht= max_count(y_test_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea186862-6779-40fb-acc0-11fe3800e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data back into vectors for classification\n",
    "X_train_copy_ht = np.reshape(X_train_ht, (-1, features*win_len))\n",
    "X_test_copy_ht = np.reshape(X_test_ht, (-1, features*win_len))\n",
    "y_train_copy_ht = y_train_ht.copy()\n",
    "y_test_copy_ht = y_test_ht.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "473c5343-9073-46b3-9c19-7ae83eb75df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_copy_ht)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_copy_ht = scaler.transform(X_train_copy_ht)\n",
    "X_test_copy_ht = scaler.transform(X_test_copy_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605568c9-0936-428f-9c18-1f591b81f485",
   "metadata": {},
   "source": [
    "#### Non-linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4f93e09-9402-4a8b-a21f-1e5358b87c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.58305345599965\n"
     ]
    }
   ],
   "source": [
    "rgr = SVR(kernel=\"rbf\")\n",
    "rgr.fit(X_train_copy_ht, y_train_copy_ht)\n",
    "\n",
    "y_pred_ht = rgr.predict(X_test_copy_ht)\n",
    "mse_SVM_ht = mean_squared_error(y_test_copy_ht, y_pred_ht)\n",
    "print(mse_SVM_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e109596-ee7d-45e3-af59-e743f5ae8148",
   "metadata": {},
   "source": [
    "MSE value is low but it needs to be compared with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b63e94-c1ab-4e87-a5f1-be49b0167fc2",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44c1e337-1cb1-4ab9-85fb-5ba2cbabca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 32)           5376      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 32)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,273\n",
      "Trainable params: 30,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ht= Sequential()\n",
    "model_ht.add(LSTM(32, input_shape= (win_len, features), return_sequences=True))\n",
    "model_ht.add(Dropout(0.5))\n",
    "model_ht.add(LSTM(64))\n",
    "model_ht.add(Dropout(0.5))\n",
    "model_ht.add(Dense(1, activation='linear'))\n",
    "model_ht.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15394a72-cb7b-4684-922c-dc1ab8e72741",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ht.compile(optimizer= 'adam', loss= 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcd8e756-964a-4520-93b1-0338e7e6832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 155s 744ms/step - loss: 25538.9746\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 144s 781ms/step - loss: 21048.5996\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 134s 724ms/step - loss: 17800.5547\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 132s 713ms/step - loss: 15036.2510\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 133s 718ms/step - loss: 12590.9277\n"
     ]
    }
   ],
   "source": [
    "# Fitting LSTM model\n",
    "LSTM = model_ht.fit(X_train_ht, y_train_ht,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76f08282-358c-4084-b693-d43efbe7c5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30012.088739422867\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model_ht.predict(X_test_ht), axis=1)\n",
    "mse = mean_squared_error(y_test_ht, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56114291-d51e-43de-af14-20ce7e35f541",
   "metadata": {},
   "source": [
    "mse value is very high!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b614a-9956-4563-ad59-585953d358f4",
   "metadata": {},
   "source": [
    "## Prediction of Subject's Weight from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc206f3e-ab9f-4b32-b271-d13a4e8b2609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting independent variables and Target Variable\n",
    "X_train_wt= Train_set_red[:, :-5]\n",
    "y_train_wt= Train_set_red[:, -3]\n",
    "X_test_wt= Test_set_red[:, :-5]\n",
    "y_test_wt= Test_set_red[:,-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66fdeb26-302a-4914-8c40-69381b8fbc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data to convert into window frames\n",
    "X_train_wt = np.reshape(X_train_wt, (-1, win_len, features)) # 3-D array\n",
    "X_test_wt = np.reshape(X_test_wt, (-1, win_len, features))\n",
    "y_train_wt = np.reshape(y_train_wt,(-1, win_len)).astype(int) # 2-D array\n",
    "y_test_wt = np.reshape(y_test_wt,(-1, win_len)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19de4754-b7db-4711-9829-10d2fd3caf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting activity class with maximum counts for each window\n",
    "y_train_wt= max_count(y_train_wt)\n",
    "y_test_wt= max_count(y_test_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1eb36e8-537a-458e-8f2c-a853ce333447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data back into vectors for classification\n",
    "X_train_copy_wt = np.reshape(X_train_wt, (-1, features*win_len))\n",
    "X_test_copy_wt = np.reshape(X_test_wt, (-1, features*win_len))\n",
    "y_train_copy_wt = y_train_wt.copy()\n",
    "y_test_copy_wt = y_test_wt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "276852f0-7937-4f8c-8090-e5a78a0fd931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_copy_wt)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_copy_wt = scaler.transform(X_train_copy_wt)\n",
    "X_test_copy_wt = scaler.transform(X_test_copy_wt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b6e694-3224-46fc-951c-f0f25b8d2260",
   "metadata": {},
   "source": [
    "#### Non-linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "884208ca-2d27-481e-88e4-9ce5430b8b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340.00484338144014\n"
     ]
    }
   ],
   "source": [
    "rgr = SVR(kernel=\"rbf\")\n",
    "rgr.fit(X_train_copy_wt, y_train_copy_wt)\n",
    "\n",
    "y_pred_wt = rgr.predict(X_test_copy_wt)\n",
    "mse_SVM_wt = mean_squared_error(y_test_copy_wt, y_pred_wt)\n",
    "print(mse_SVM_wt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2df077f-1d0d-4a1e-967f-e64c2d389c6a",
   "metadata": {},
   "source": [
    "MSE value is very high, however it needs to be compared with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2bf083-7989-45d1-b844-b06422cddaae",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3158456-aba2-4034-99d9-84552e8ec6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wt= Sequential()\n",
    "model_wt.add(LSTM(32, input_shape= (win_len, features), return_sequences=True))\n",
    "model_wt.add(Dropout(0.5))\n",
    "model_wt.add(LSTM(64))\n",
    "model_wt.add(Dropout(0.5))\n",
    "model_wt.add(Dense(1, activation='linear'))\n",
    "model_wt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e0203-0e25-4d48-98b4-7978f19a570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wt.compile(optimizer= 'adam', loss= 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66b31f-ee06-4114-8cf9-209e93256cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting LSTM model\n",
    "LSTM = model_wt.fit(X_train_wt, y_train_wt,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f1576-c756-44b3-af5c-307dfd31ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model_wt.predict(X_test_wt), axis=1)\n",
    "mse = mean_squared_error(y_test_wt, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e5603f-ac1c-4904-8773-7cda528f631e",
   "metadata": {},
   "source": [
    "mse value is very high in comparison to SVR meaning the error terms are much higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a302d-d17d-47ed-af72-2ee59640ee4c",
   "metadata": {},
   "source": [
    "## Calculating BMI and classification of BMI from data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88336b82-4e0c-41cc-814c-c7144a99f6c3",
   "metadata": {},
   "source": [
    "From background knowledge it is considered that maybe gravity columns can provide some useful information as weight of a subject has some correlatios with gravity. Can try keeping the gravity columns as independent variables whilst building the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3a421cd-12eb-4b78-8954-0df917013cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating column BMI from Weight and Height\n",
    "BMI_Dataset= Labeled_data.copy(deep= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4ba3ee0-fe71-4b0b-a681-4c8c6cc5241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMI_Dataset['BMI']= BMI_Dataset['weight'] / ((BMI_Dataset['height'] * 0.01)** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27c3cb5b-ebb2-44a4-849d-0193c24db61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude.roll</th>\n",
       "      <th>attitude.pitch</th>\n",
       "      <th>attitude.yaw</th>\n",
       "      <th>gravity.x</th>\n",
       "      <th>gravity.y</th>\n",
       "      <th>gravity.z</th>\n",
       "      <th>rotationRate.x</th>\n",
       "      <th>rotationRate.y</th>\n",
       "      <th>rotationRate.z</th>\n",
       "      <th>userAcceleration.x</th>\n",
       "      <th>userAcceleration.y</th>\n",
       "      <th>userAcceleration.z</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Activity</th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.528132</td>\n",
       "      <td>-0.733896</td>\n",
       "      <td>0.696372</td>\n",
       "      <td>0.741895</td>\n",
       "      <td>0.669768</td>\n",
       "      <td>-0.031672</td>\n",
       "      <td>0.316738</td>\n",
       "      <td>0.778180</td>\n",
       "      <td>1.082764</td>\n",
       "      <td>0.294894</td>\n",
       "      <td>-0.184493</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>28.859212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.527992</td>\n",
       "      <td>-0.716987</td>\n",
       "      <td>0.677762</td>\n",
       "      <td>0.753099</td>\n",
       "      <td>0.657116</td>\n",
       "      <td>-0.032255</td>\n",
       "      <td>0.842032</td>\n",
       "      <td>0.424446</td>\n",
       "      <td>0.643574</td>\n",
       "      <td>0.219405</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>0.114866</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>28.859212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.527765</td>\n",
       "      <td>-0.706999</td>\n",
       "      <td>0.670951</td>\n",
       "      <td>0.759611</td>\n",
       "      <td>0.649555</td>\n",
       "      <td>-0.032707</td>\n",
       "      <td>-0.138143</td>\n",
       "      <td>-0.040741</td>\n",
       "      <td>0.343563</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.134701</td>\n",
       "      <td>-0.167808</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>28.859212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.516768</td>\n",
       "      <td>-0.704678</td>\n",
       "      <td>0.675735</td>\n",
       "      <td>0.760709</td>\n",
       "      <td>0.647788</td>\n",
       "      <td>-0.041140</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>-1.048717</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>-0.008389</td>\n",
       "      <td>0.136788</td>\n",
       "      <td>0.094958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>28.859212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493941</td>\n",
       "      <td>-0.703918</td>\n",
       "      <td>0.672994</td>\n",
       "      <td>0.760062</td>\n",
       "      <td>0.647210</td>\n",
       "      <td>-0.058530</td>\n",
       "      <td>0.114253</td>\n",
       "      <td>-0.912890</td>\n",
       "      <td>0.047341</td>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.353996</td>\n",
       "      <td>-0.044299</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>28.859212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attitude.roll  attitude.pitch  attitude.yaw  gravity.x  gravity.y  \\\n",
       "0       1.528132       -0.733896      0.696372   0.741895   0.669768   \n",
       "1       1.527992       -0.716987      0.677762   0.753099   0.657116   \n",
       "2       1.527765       -0.706999      0.670951   0.759611   0.649555   \n",
       "3       1.516768       -0.704678      0.675735   0.760709   0.647788   \n",
       "4       1.493941       -0.703918      0.672994   0.760062   0.647210   \n",
       "\n",
       "   gravity.z  rotationRate.x  rotationRate.y  rotationRate.z  \\\n",
       "0  -0.031672        0.316738        0.778180        1.082764   \n",
       "1  -0.032255        0.842032        0.424446        0.643574   \n",
       "2  -0.032707       -0.138143       -0.040741        0.343563   \n",
       "3  -0.041140       -0.025005       -1.048717        0.035860   \n",
       "4  -0.058530        0.114253       -0.912890        0.047341   \n",
       "\n",
       "   userAcceleration.x  userAcceleration.y  userAcceleration.z  Subject  \\\n",
       "0            0.294894           -0.184493            0.377542        1   \n",
       "1            0.219405            0.035846            0.114866        1   \n",
       "2            0.010714            0.134701           -0.167808        1   \n",
       "3           -0.008389            0.136788            0.094958        1   \n",
       "4            0.199441            0.353996           -0.044299        1   \n",
       "\n",
       "   Activity  gender  weight  height  age        BMI  \n",
       "0         0       1     102     188   46  28.859212  \n",
       "1         0       1     102     188   46  28.859212  \n",
       "2         0       1     102     188   46  28.859212  \n",
       "3         0       1     102     188   46  28.859212  \n",
       "4         0       1     102     188   46  28.859212  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BMI_Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79d458bb-c8ed-49e2-9ff7-6502ce865e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1182344, 19)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test-Train Split\n",
    "BMI_Train= BMI_Dataset.loc[BMI_Dataset['Subject'] <= 20]\n",
    "BMI_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea616f03-4615-4e87-92eb-38fb563572f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230521, 19)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BMI_Test= BMI_Dataset.loc[BMI_Dataset['Subject'] > 20]\n",
    "BMI_Test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba507ce-6f86-499a-a5bf-430db40dd5e7",
   "metadata": {},
   "source": [
    "#### With all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84dea83f-e58b-4af1-816f-2d23242d2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Subject column as it does not add any useful information but keeping the gravity columns\n",
    "BMI_Train_full= BMI_Train.drop(['Subject'], axis=1)\n",
    "BMI_Test_full= BMI_Test.drop(['Subject'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64fab0b6-8e7c-4d05-b119-ebbfe6f8c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalisation\n",
    "BMI_Train_full= BMI_Train_full.to_numpy()  # converting pandas dataframe to numpy array\n",
    "BMI_Test_full= BMI_Test_full.to_numpy()\n",
    "\n",
    "# subtracting by mean and dividing by standard deviation of independent variables\n",
    "mean= np.mean(BMI_Train_full[:,:-6], axis=0)\n",
    "std = np.std(BMI_Train_full[:,:-6], axis=0)\n",
    "BMI_Train_full[:,:-6] = (BMI_Train_full[:,:-6]-mean) / std\n",
    "BMI_Test_full[:,:-6] = (BMI_Test_full[:,:-6]-mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efa73f0f-26f3-444e-b577-4cd0effc195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "win_len = 100\n",
    "features = BMI_Train_full.shape[1]-6 #minus the label col\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9d58ade-9a4a-4119-8191-036998910908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2364500, 18)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Sliding Window with 50% overlap\n",
    "BMI_Train_full = sliding_window(BMI_Train_full, 100)\n",
    "BMI_Train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e275d46f-48cc-4d70-95c9-fdbc79c85749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(460900, 18)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BMI_Test_full = sliding_window(BMI_Test_full, 100)\n",
    "BMI_Test_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93b508cf-27c0-41db-9ded-7b58eda2b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting independent variables and Target Variable\n",
    "X_train_bmi= BMI_Train_full[:, :-6]\n",
    "y_train_bmi= BMI_Train_full[:, -1]\n",
    "X_test_bmi= BMI_Test_full[:, :-6]\n",
    "y_test_bmi= BMI_Test_full[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d29ffd79-98f7-4de9-a3d0-6e5ca8f84679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting BMI to categorical\n",
    "y_train_bmi_cat= np.digitize(y_train_bmi, bins=[18.5,24.9,29.9])\n",
    "y_test_bmi_cat= np.digitize(y_test_bmi, bins=[18.5,24.9,29.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71497a1e-8d5a-41f6-b3e3-f9f084a2e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data to convert into window frames\n",
    "X_train_bmi = np.reshape(X_train_bmi, (-1, win_len, features)) # 3-D array\n",
    "X_test_bmi = np.reshape(X_test_bmi, (-1, win_len, features))\n",
    "y_train_bmi = np.reshape(y_train_bmi_cat,(-1, win_len)).astype(int) # 2-D array\n",
    "y_test_bmi = np.reshape(y_test_bmi_cat,(-1, win_len)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b092d4a2-8114-47c9-a18b-81f7c0ed4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting target variable class with maximum counts for each window\n",
    "y_train_bmi= max_count(y_train_bmi)\n",
    "y_test_bmi= max_count(y_test_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "213d8447-2ab0-4bc5-bbfe-50e1951d3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data back into vectors for classification\n",
    "X_train_copy_bmi = np.reshape(X_train_bmi, (-1, features*win_len))\n",
    "X_test_copy_bmi = np.reshape(X_test_bmi, (-1, features*win_len))\n",
    "y_train_copy_bmi = y_train_bmi.copy()\n",
    "y_test_copy_bmi = y_test_bmi.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7668e53-c8f8-4ad5-ac41-aed5bea51457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3.]), array([ 1046, 14045,  7246,  1308], dtype=int64))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_copy_bmi, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b39594b1-0515-4acd-bfed-094a7903893f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2.]), array([3488, 1121], dtype=int64))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_copy_bmi, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d7af324-cde7-4865-a8b4-b98a3167ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_copy_bmi)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_copy_bmi = scaler.transform(X_train_copy_bmi)\n",
    "X_test_copy_bmi = scaler.transform(X_test_copy_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fce2fd-9540-4c9c-b936-b1df80e121c2",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "871f54d4-c18f-4a1b-a8b0-4aded4a58535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6641353872857453\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver= 'liblinear')\n",
    "clf.fit(X_train_copy_bmi, y_train_copy_bmi)\n",
    "\n",
    "y_pred_bmi = clf.predict(X_test_copy_bmi)\n",
    "acc_LR_bmi = accuracy_score(y_test_copy_bmi, y_pred_bmi)\n",
    "print(acc_LR_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b3367-2ffb-47f2-887e-72f53f44012d",
   "metadata": {},
   "source": [
    "#### Non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a46e565e-3da4-44b9-8560-fb9389642ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7817313950965502\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel=\"rbf\")\n",
    "clf.fit(X_train_copy_bmi, y_train_copy_bmi)\n",
    "\n",
    "y_pred_bmi = clf.predict(X_test_copy_bmi)\n",
    "acc_SVM_bmi = accuracy_score(y_test_copy_bmi, y_pred_bmi)\n",
    "print(acc_SVM_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f98452-5bc7-440b-8c3b-5791a091f429",
   "metadata": {},
   "source": [
    "Still the accuracy score is very low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8492557b-566c-4bd6-b369-b162d79185e4",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9abcb010-aad7-4561-a941-f089bf889f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6584942503796919\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_copy_bmi, y_train_copy_bmi)\n",
    "\n",
    "y_pred_bmi = clf.predict(X_test_copy_bmi)\n",
    "acc_RF_bmi = accuracy_score(y_test_copy_bmi, y_pred_bmi)\n",
    "print(acc_RF_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d5e63-84cd-46b8-af74-1c5ecec5185a",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7e8f922-5582-40fe-a408-d2684f8b196f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6784551963549577\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train_copy_bmi, y_train_copy_bmi)\n",
    "\n",
    "y_pred_bmi = clf.predict(X_test_copy_bmi)\n",
    "acc_KNN_bmi = accuracy_score(y_test_copy_bmi, y_pred_bmi)\n",
    "print(acc_KNN_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684a7139-5f62-4fa6-a97d-06a98112deb7",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1403bad-e86b-44d7-86a5-694a5424e0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:55:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7639401171620742\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(use_label_encoder=False)\n",
    "clf.fit(X_train_copy_bmi, y_train_copy_bmi)\n",
    "\n",
    "y_pred_bmi = clf.predict(X_test_copy_bmi)\n",
    "acc_XGB_bmi = accuracy_score(y_test_copy_bmi, y_pred_bmi)\n",
    "print(acc_XGB_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f20fa81-c9d3-4cad-82cb-a93c09020c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model  Accuracy Score\n",
      "0              LR        0.664135\n",
      "1  Non-linear SVM        0.781731\n",
      "2   RF Classifier        0.658494\n",
      "3             KNN        0.678455\n",
      "4  XGB Classifier        0.763940\n"
     ]
    }
   ],
   "source": [
    "# Collating output from all models\n",
    "Accuracy_bmi_ML= pd.DataFrame({\"Model\": [\"LR\", \"Non-linear SVM\", \"RF Classifier\", \"KNN\", \"XGB Classifier\"],\n",
    "                               \"Accuracy Score\": [acc_LR_bmi, acc_SVM_bmi, acc_RF_bmi, acc_KNN_bmi, acc_XGB_bmi]})\n",
    "print(Accuracy_bmi_ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43487f3-557f-42e5-aa3d-c0e2406c821c",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "413d4702-d4cd-43e3-ac7a-ec5f97d812e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for labels\n",
    "classes= 4\n",
    "y_train_LSTM = keras.utils.np_utils.to_categorical(y_train_bmi, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc66702a-04dd-4aae-ae52-572086e981e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 32)           5760      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 100, 32)           0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4)                 12804     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,564\n",
      "Trainable params: 18,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bmi= Sequential()\n",
    "model_bmi.add(LSTM(32, input_shape= (win_len, features), return_sequences=True))\n",
    "model_bmi.add(Dropout(0.5))\n",
    "model_bmi.add(Flatten())\n",
    "model_bmi.add(Dense(4, activation='softmax'))\n",
    "model_bmi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d56b8db-28cb-456d-a40c-e6f82f66c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bmi.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6113d443-1f03-4d9f-90fe-00b76091760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 51s 235ms/step - loss: 0.1399 - accuracy: 0.9535\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 45s 244ms/step - loss: 0.1223 - accuracy: 0.9588\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 44s 240ms/step - loss: 0.1076 - accuracy: 0.9645\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 45s 242ms/step - loss: 0.0934 - accuracy: 0.9679\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 44s 240ms/step - loss: 0.1195 - accuracy: 0.9628\n"
     ]
    }
   ],
   "source": [
    "# Fitting LSTM model\n",
    "LSTM = model_bmi.fit(X_train_bmi, y_train_LSTM,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d653a006-ea17-4863-a2b8-0331fc2b3a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7756563245823389\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model_bmi.predict(X_test_bmi), axis=1)\n",
    "acc = accuracy_score(y_test_bmi, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a924ca3-eb66-4926-85f7-0ef44ef70842",
   "metadata": {},
   "source": [
    "Prediction accuracy of 78% is achieved. Can also try CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ab60f-c92e-4086-b24f-a1410ad57410",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "726b740b-c9c9-41a5-b958-d97ea4713b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 100, 12, 16)       128       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 100, 6, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100, 6, 16)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9600)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                153616    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153,812\n",
      "Trainable params: 153,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(16, kernel_size=(1, 7), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc6a14c7-b3d5-4673-bb40-825a06fc4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da60a2df-69b0-4288-a42e-203e61b69a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 95s 284ms/step - loss: 0.9987 - accuracy: 0.6091\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 59s 317ms/step - loss: 0.9005 - accuracy: 0.6348\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 53s 286ms/step - loss: 0.8654 - accuracy: 0.6409\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 51s 278ms/step - loss: 0.8367 - accuracy: 0.6478\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 59s 319ms/step - loss: 0.8204 - accuracy: 0.6501\n"
     ]
    }
   ],
   "source": [
    "# Fitting model\n",
    "CNN = model.fit(X_train_bmi, y_train_LSTM,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b792f0c0-37c9-4749-8bd6-983c7aa48172",
   "metadata": {},
   "source": [
    "Model is showing low accuracy. Can try by increasing the number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4dd7667-6677-48de-909d-8229a966a0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 100, 12, 32)       256       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 100, 6, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100, 6, 32)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 19200)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                614432    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 614,820\n",
      "Trainable params: 614,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(32, kernel_size=(1, 7), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19df6fc5-ea67-4602-bb77-d20334518844",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "685c460f-690e-4894-98d4-281c0708b558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 106s 551ms/step - loss: 0.9681 - accuracy: 0.5835\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 100s 543ms/step - loss: 0.8518 - accuracy: 0.5968\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 94s 507ms/step - loss: 0.8138 - accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 95s 515ms/step - loss: 0.7876 - accuracy: 0.6073\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 115s 624ms/step - loss: 0.7740 - accuracy: 0.6074\n"
     ]
    }
   ],
   "source": [
    "# Fitting model\n",
    "CNN = model.fit(X_train_bmi, y_train_LSTM,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e2adf0-9281-4f7f-8ede-701565435412",
   "metadata": {},
   "source": [
    "Can try with similar architecture from final model of classification of activity, if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18cca524-c34c-4533-a842-fd48161031cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 100, 12, 64)       512       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 100, 6, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100, 6, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 100, 6, 64)        28736     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 100, 3, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 100, 3, 64)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 19200)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                1228864   \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,258,372\n",
      "Trainable params: 1,258,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(64, kernel_size=(1, 7), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, kernel_size=(1, 7), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f5c6d0bd-0655-4b47-9564-67745804d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5883a45e-2aaf-4273-b849-dac8b22b8c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 681s 4s/step - loss: 0.9272 - accuracy: 0.6091\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 548s 3s/step - loss: 0.6521 - accuracy: 0.7108\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 534s 3s/step - loss: 0.5134 - accuracy: 0.7896\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 536s 3s/step - loss: 0.4190 - accuracy: 0.8384\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 570s 3s/step - loss: 0.3594 - accuracy: 0.8690\n"
     ]
    }
   ],
   "source": [
    "# Fitting model\n",
    "CNN = model.fit(X_train_bmi, y_train_LSTM,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d147c2ca-4a15-470e-a567-ad965d735c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7008027771750922\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test_bmi), axis=1)\n",
    "acc = accuracy_score(y_test_bmi, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0e672-da50-46fa-8694-034550da39c1",
   "metadata": {},
   "source": [
    "Prediction Accuracy score is lower than training accuracy score indicating some level of over-fitting issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99002420-09ab-4ad2-b8ae-dd43b233c659",
   "metadata": {},
   "source": [
    "#### With reduced variable set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc977bd1-4a73-4df6-b1b6-356345b0df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Subject and gravity columns\n",
    "BMI_Train_red= BMI_Train.drop(['Subject', 'gravity.x', 'gravity.y', 'gravity.z'], axis=1)\n",
    "BMI_Test_red= BMI_Test.drop(['Subject', 'gravity.x', 'gravity.y', 'gravity.z'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dcce43c-b192-41ae-ae0c-d0f8d44cdf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalisation\n",
    "BMI_Train_red= BMI_Train_red.to_numpy()  # converting pandas dataframe to numpy array\n",
    "BMI_Test_red= BMI_Test_red.to_numpy()\n",
    "\n",
    "# subtracting by mean and dividing by standard deviation of independent variables\n",
    "mean= np.mean(BMI_Train_red[:,:-6], axis=0)\n",
    "std = np.std(BMI_Train_red[:,:-6], axis=0)\n",
    "BMI_Train_red[:,:-6] = (BMI_Train_red[:,:-6]-mean) / std\n",
    "BMI_Test_red[:,:-6] = (BMI_Test_red[:,:-6]-mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc302fed-a147-45a9-9437-98ef747cb765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "win_len = 100\n",
    "features = BMI_Train_red.shape[1]-6 #minus the label col\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03b1241a-c8a7-4f9c-9be7-8a37741ddbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2364500, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Sliding Window with 50% overlap\n",
    "BMI_Train_red = sliding_window(BMI_Train_red, 100)\n",
    "BMI_Train_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73ab8828-d538-47af-a763-25c8a8bd6b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(460900, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BMI_Test_red = sliding_window(BMI_Test_red, 100)\n",
    "BMI_Test_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f44dd4ed-133d-4efe-a9a6-98b35ceeb933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting independent variables and Target Variable\n",
    "X_train_bmi= BMI_Train_red[:, :-6]\n",
    "y_train_bmi= BMI_Train_red[:, -1]\n",
    "X_test_bmi= BMI_Test_red[:, :-6]\n",
    "y_test_bmi= BMI_Test_red[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f54045ad-831e-40d0-83ec-e2b387d062a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting BMI to categorical\n",
    "y_train_bmi_cat= np.digitize(y_train_bmi, bins=[18.5,24.9,29.9])\n",
    "y_test_bmi_cat= np.digitize(y_test_bmi, bins=[18.5,24.9,29.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8612580a-7082-4695-a682-717a16d78946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data to convert into window frames\n",
    "X_train_bmi = np.reshape(X_train_bmi, (-1, win_len, features)) # 3-D array\n",
    "X_test_bmi = np.reshape(X_test_bmi, (-1, win_len, features))\n",
    "y_train_bmi = np.reshape(y_train_bmi_cat,(-1, win_len)).astype(int) # 2-D array\n",
    "y_test_bmi = np.reshape(y_test_bmi_cat,(-1, win_len)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75fa794b-6b8b-4a4f-aca9-40b270f0d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting target variable class with maximum counts for each window\n",
    "y_train_bmi= max_count(y_train_bmi)\n",
    "y_test_bmi= max_count(y_test_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0af8659f-3f65-452a-8bc2-f739d93bfbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data back into vectors for classification\n",
    "X_train_copy_bmi = np.reshape(X_train_bmi, (-1, features*win_len))\n",
    "X_test_copy_bmi = np.reshape(X_test_bmi, (-1, features*win_len))\n",
    "y_train_copy_bmi = y_train_bmi.copy()\n",
    "y_test_copy_bmi = y_test_bmi.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6390a113-aa10-414d-ac10-e1efbdd5cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_copy_bmi)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_copy_bmi = scaler.transform(X_train_copy_bmi)\n",
    "X_test_copy_bmi = scaler.transform(X_test_copy_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed65c588-c387-423b-aab0-9d864c59aa6b",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "661a4349-652a-43e8-a723-6a19d484d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6712952918203515\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver= 'liblinear')\n",
    "clf.fit(X_train_copy_bmi, y_train_copy_bmi)\n",
    "\n",
    "y_pred_bmi = clf.predict(X_test_copy_bmi)\n",
    "acc_LR_bmi = accuracy_score(y_test_copy_bmi, y_pred_bmi)\n",
    "print(acc_LR_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6344c1-eae1-44e2-88d0-a6501ef0e1e3",
   "metadata": {},
   "source": [
    "#### Non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3e7efce2-377d-4a13-b166-a20476f98ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7498372748969407\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel= 'rbf')\n",
    "clf.fit(X_train_copy_bmi, y_train_copy_bmi)\n",
    "\n",
    "y_pred_bmi = clf.predict(X_test_copy_bmi)\n",
    "acc_SVM_bmi = accuracy_score(y_test_copy_bmi, y_pred_bmi)\n",
    "print(acc_SVM_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1460adf-73e8-44c4-8ba3-90dae70f6468",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "654999c4-7178-4a52-bf0e-17236bb84ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738771967888913\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_copy_bmi, y_train_copy_bmi)\n",
    "\n",
    "y_pred_bmi = clf.predict(X_test_copy_bmi)\n",
    "acc_RF_bmi = accuracy_score(y_test_copy_bmi, y_pred_bmi)\n",
    "print(acc_RF_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ee3af9-b56b-4241-aa68-39e213c4e136",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db2b5929-09d7-4d4d-b77c-d2818b25de61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6563245823389021\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train_copy_bmi, y_train_copy_bmi)\n",
    "\n",
    "y_pred_bmi = clf.predict(X_test_copy_bmi)\n",
    "acc_KNN_bmi = accuracy_score(y_test_copy_bmi, y_pred_bmi)\n",
    "print(acc_KNN_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c02dc9-4fac-4358-ba62-b127112db18d",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "40d634b0-e0fe-4c5d-b602-170a75c40d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7129529182035148\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(use_label_encoder=False)\n",
    "clf.fit(X_train_copy_bmi, y_train_copy_bmi)\n",
    "\n",
    "y_pred_bmi = clf.predict(X_test_copy_bmi)\n",
    "acc_XGB_bmi = accuracy_score(y_test_copy_bmi, y_pred_bmi)\n",
    "print(acc_XGB_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d91455f-be00-4661-b6d8-9acc8586148c",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc9ee88d-693f-4301-ae5a-6a65292b4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for labels\n",
    "classes= 4\n",
    "y_train_LSTM = keras.utils.np_utils.to_categorical(y_train_bmi, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "358cab48-c343-4399-a51d-3fb12e7307f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 32)           5376      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 32)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 12804     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,180\n",
      "Trainable params: 18,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bmi= Sequential()\n",
    "model_bmi.add(LSTM(32, input_shape= (win_len, features), return_sequences=True))\n",
    "model_bmi.add(Dropout(0.5))\n",
    "model_bmi.add(Flatten())\n",
    "model_bmi.add(Dense(4, activation='softmax'))\n",
    "model_bmi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "078fca60-5d91-4a83-aed6-3ab7cc12c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bmi.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edb286c7-761c-483e-9edf-c28629d7bb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 59s 242ms/step - loss: 0.7880 - accuracy: 0.6532\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 46s 248ms/step - loss: 0.4856 - accuracy: 0.7901\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 44s 239ms/step - loss: 0.3390 - accuracy: 0.8652\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 45s 242ms/step - loss: 0.2699 - accuracy: 0.8979\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 44s 239ms/step - loss: 0.2115 - accuracy: 0.9225\n"
     ]
    }
   ],
   "source": [
    "# Fitting LSTM model\n",
    "LSTM = model_bmi.fit(X_train_bmi, y_train_LSTM,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c24945f6-b998-4ca3-9260-2217f5d6c889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7049251464525927\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model_bmi.predict(X_test_bmi), axis=1)\n",
    "acc = accuracy_score(y_test_bmi, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8cba2-a75d-4a84-acd4-5160b1e0ec53",
   "metadata": {},
   "source": [
    "There are still some over-fitting issues but prediction accuracy score is decent. However, some of the models with all variables like LSTM, non-linear SVM have been better performing already."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1966c5-0685-4569-bf56-5cacd2a2f1eb",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a14d0020-9acb-4d95-83a7-b16a645179ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 100, 9, 64)        512       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 100, 4, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 100, 4, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 100, 4, 64)        28736     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 100, 2, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 100, 2, 64)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                819264    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 848,772\n",
      "Trainable params: 848,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential() # initialising\n",
    "model.add(Conv2D(64, kernel_size=(1, 7), activation='relu', padding='same', input_shape=(win_len, features, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, kernel_size=(1, 7), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "56c92e66-2656-4435-9d88-d11fa09c1e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bf272e85-2971-4a92-9c3a-3a4c67569661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "185/185 [==============================] - 612s 3s/step - loss: 0.8975 - accuracy: 0.6108\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 619s 3s/step - loss: 0.6480 - accuracy: 0.7100\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 647s 3s/step - loss: 0.5161 - accuracy: 0.7847\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 487s 3s/step - loss: 0.4226 - accuracy: 0.8366\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 367s 2s/step - loss: 0.3615 - accuracy: 0.8643\n"
     ]
    }
   ],
   "source": [
    "# Fitting model\n",
    "CNN = model.fit(X_train_bmi, y_train_LSTM,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "00dca26f-e471-456b-b33c-4abadfb91472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7177261878932524\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test_bmi), axis=1)\n",
    "acc = accuracy_score(y_test_bmi, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244559b-4754-4901-b96b-e8e2c4e44103",
   "metadata": {},
   "source": [
    "#### Overall summary for classification of BMI from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31353dc3-3eb6-4fcc-9937-8dad646d3ea1",
   "metadata": {},
   "source": [
    "Most of the models have been able to achieve accuracy score above 70%. Inclusion or removal of gravity columns didn’t make much difference in predictive performance. Models with bagging (non-linear SVM) and boosting (XGBoost) algorithm were also giving equivalent performance as deep learning model (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9691f2d5-f15b-4fae-a639-8f95e7d7d257",
   "metadata": {},
   "source": [
    "## Key images for Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "69969efd-3066-42d8-abf6-70501135cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model  Activity  Gender  Age  BMI\n",
      "0              LR        51      62   46   66\n",
      "1  Non-linear SVM        79      55   48   78\n",
      "2              RF        60      54   41   66\n",
      "3             KNN        38      50   51   68\n",
      "4         XGBoost        76      54   42   76\n",
      "5            LSTM        93      59   42   78\n",
      "6             CNN        88      53   49   70\n"
     ]
    }
   ],
   "source": [
    "Accuracy_scores= pd.DataFrame({\"Model\": [\"LR\", \"Non-linear SVM\", \"RF\", \"KNN\", \"XGBoost\", \"LSTM\", \"CNN\"],\n",
    "                                \"Activity\": [51, 79, 60, 38, 76, 93, 88],\n",
    "                                \"Gender\": [62, 55, 54, 50, 54, 59, 53],\n",
    "                                \"Age\": [46, 48, 41, 51, 42, 42, 49],\n",
    "                                \"BMI\": [66, 78, 66, 68, 76, 78, 70]})\n",
    "print(Accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a9861400-9ace-4833-bd6f-8d245360e52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Accuracy_scores.plot(x=\"Model\", y=[\"Activity\", \"Gender\", \"Age\", \"BMI\"], kind=\"line\", figsize=(5, 5))\n",
    "plt.ylabel(\"Percent Accuracy Score\")\n",
    "plt.savefig('Accuracy_scores.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931e80a-3c55-45da-8443-a5ddb29cd629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
